diff --git a/.gitignore b/.gitignore
index f56ff2a..2089c7a 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,6 +1,9 @@
 data/*
 README_local_only.md
 outputs/*
+outputs_V0/*
+outputs_igarss/*
+figures/
 *.out
 *.log
 wandb/*
diff --git a/.vscode/launch.json b/.vscode/launch.json
index 92037d2..b069de5 100644
--- a/.vscode/launch.json
+++ b/.vscode/launch.json
@@ -4,13 +4,6 @@
     // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
     "version": "0.2.0",
     "configurations": [
-        {
-            "name": "Python: Current File",
-            "type": "python",
-            "request": "launch",
-            "program": "${file}",
-            "console": "integratedTerminal"
-        },
         {
             "name": "Python: Current File",
             "type": "python",
@@ -18,7 +11,8 @@
             "program": "${file}",
             "console": "integratedTerminal",
             "env": {
-                "PYTHONPATH": "/geoinfo_vol1/home/p/u/puzhao/miniforge3/envs/pytorch/bin/python"
+                "PYTHONPATH": "/geoinfo_vol1/home/p/u/puzhao/miniforge3/envs/pytorch/bin/python",
+                "CUDA_VISIBLE_DEVICES": "7",
             },
         }
     ]
diff --git a/README.md b/README.md
index 56bec40..c50d240 100644
--- a/README.md
+++ b/README.md
@@ -16,4 +16,50 @@ scp -r D:\wildfire-s1s2-dataset-ca-2019-median-tiles-V1\test_images\* puzhao@alv
 # SNIC to geoinfo-gpu
 scp -r puzhao@alvis1.c3se.chalmers.se:/cephyr/NOBACKUP/groups/snic2021-7-104/puzhao-snic-500G/smp-seg-pytorch/main_s1s2_fuse_unet_V1.py /home/p/u/puzhao/smp-seg-pytorch/main_s1s2_fuse_unet_V1.py
 
-scp -r /home/p/u/puzhao/smp-seg-pytorch/fcnn4cd/paddle_unet.py puzhao@alvis1.c3se.chalmers.se:/cephyr/NOBACKUP/groups/snic2021-7-104/puzhao-snic-500G/smp-seg-pytorch/fcnn4cd
\ No newline at end of file
+scp -r /home/p/u/puzhao/smp-seg-pytorch/fcnn4cd/paddle_unet.py puzhao@alvis1.c3se.chalmers.se:/cephyr/NOBACKUP/groups/snic2021-7-104/puzhao-snic-500G/smp-seg-pytorch/fcnn4cd
+
+
+
+# Paddle Installation
+https://www.paddlepaddle.org.cn/install/quick?docurl=/documentation/docs/zh/install/conda/linux-conda.html
+
+# change permission
+<!-- https://linuxize.com/post/chmod-command-in-linux/ -->
+chmod [OPTIONS] [ugoa…][-+=]perms…[,…] FILE...
+chmod u=rwx,g=r,o= filename
+
+u - The file owner.
+g - The users who are members of the group.
+o - All other users.
+a - All users, identical to ugo.
+
+-rw-r--r-- 12 linuxize users 12.0K Apr  8 20:51 filename.txt
+|[-][-][-]-   [------] [---]
+| |  |  | |      |       |
+| |  |  | |      |       +-----------> 7. Group
+| |  |  | |      +-------------------> 6. Owner
+| |  |  | +--------------------------> 5. Alternate Access Method
+| |  |  +----------------------------> 4. Others Permissions
+| |  +-------------------------------> 3. Group Permissions
+| +----------------------------------> 2. Owner Permissions
++------------------------------------> 1. File Type
+
+chmod 744 /home/p/u/puzhao/wildfire-s1s2-dataset-ca-tiles
+-rw------- (600) -- Only the user has read and write permissions.
+-rw-r--r-- (644) -- Only user has read and write permissions; the group and others can read only.
+-rwx------ (700) -- Only the user has read, write and execute permissions.
+-rwxr-xr-x (755) -- The user has read, write and execute permissions; the group and others can only read and execute.
+-rwx--x--x (711) -- The user has read, write and execute permissions; the group and others can only execute.
+-rw-rw-rw- (666) -- Everyone can read and write to the file. Bad idea.
+-rwxrwxrwx (777) -- Everyone can read, write and execute. Another bad idea.
+
+r (read) = 4
+w (write) = 2
+x (execute) = 1
+no permissions = 0
+
+Owner: rwx=4+2+1=7
+Group: r-x=4+0+1=5
+Others: r-x=4+0+0=4
+
+chmod a+rw 
\ No newline at end of file
diff --git a/config/mtbs_cfg.yaml b/config/mtbs_cfg.yaml
deleted file mode 100644
index abb222b..0000000
--- a/config/mtbs_cfg.yaml
+++ /dev/null
@@ -1,38 +0,0 @@
-project:
-    name: MTBS
-
-data:
-    name: mtbs
-    useDataWoCAug: False
-    CLASSES: ['unburn', 'low', 'moderate', 'high', 'greener', 'cloud']
-    SEED: 42
-    random_state: 42
-
-model:
-    ARCH: UNet
-    ACTIVATION: sigmoid
-    ENCODER: resnet18 # 'mobilenet_v2'
-    ENCODER_WEIGHTS: imagenet
-    INPUT_CHANNELS: 12
-
-    max_epoch: 10
-    batch_size: 16
-    learning_rate: 1e-4
-    weight_decay: 1e-4
-    
-
-    use_lr_scheduler: False
-    warmup_coef: 2
-    
-    max_score: 0.1 # If IoU > max_score, start to save model
-
-    verbose: True
-
-experiment:
-    note: dft
-    name: ${data.name}_${model.ARCH}_${model.ENCODER}_${experiment.note}
-    output: ./outputs/run_${experiment.name}_${now:%Y%m%dT%H%M%S} #${defaults.0.data}
-
-hydra:
-    run:
-        dir: ${experiment.output}
\ No newline at end of file
diff --git a/config/s1s2_cfg_prg.yaml b/config/s1s2_cfg_prg.yaml
index 19762b5..cdf445e 100644
--- a/config/s1s2_cfg_prg.yaml
+++ b/config/s1s2_cfg_prg.yaml
@@ -1,64 +1,82 @@
-project:
-    name: s1s2-snic-test
-    entity: wildfire
-
-data:
-    # dir: /cephyr/NOBACKUP/groups/snic2021-7-104/wildfire-s1s2-dataset-ak-tiles
-    # dir: /cephyr/NOBACKUP/groups/snic2021-7-104/wildfire-s1s2-dataset-ak-tiles
-    # dir: /cephyr/NOBACKUP/groups/snic2021-7-104/puzhao-snic-500G/US_2021_Dixie
-    dir: /cephyr/NOBACKUP/groups/snic2021-7-104/puzhao-snic-500G/CA_2021_Kamloops
-    # dir: D:\wildfire-s1s2-dataset-ak-tiles
-
-    name: s1s2
-    satellites: ['S1']
-    prepost: ['pre', 'post']
-    stacking: True
+
+# defaults:
+#     - s1s2_unet: s1
+
+PROJECT:
+    NAME: IGARSS-2022
+    ENTITY: wildfire
+
+RAND: # Rrproduce Results
+    SEED: 42
+    DETERMIN: True
+
+DATA:
+    NAME: s1s2
+    # DIR: /home/p/u/puzhao/wildfire-s1s2-dataset-ca-tiles
+    # DIR: /cephyr/NOBACKUP/groups/snic2021-7-104/wildfire-s1s2-dataset-ak-tiles
+    # DIR: /cephyr/NOBACKUP/groups/snic2021-7-104/wildfire-s1s2-dataset-ca-tiles
+    DIR: /home/p/u/puzhao/wildfire-progression-dataset/CA_2021_Kamloops
+
+    SATELLITES: ['S1']
+    PREPOST: ['pre','post']
+    STACKING: True # stack bi-temporal data
 
     ALL_BANDS:
-        S1: ['ND', 'VH', 'VV']
         ALOS: ['ND', 'VH', 'VV']
+        S1: ['ND', 'VH', 'VV']
         S2: ['B2', 'B3', 'B4', 'B8', 'B11', 'B12']
 
     INPUT_BANDS:
-        S1: ['ND', 'VH', 'VV']
         ALOS: ['ND', 'VH', 'VV']
-        S2: ['B8', 'B11', 'B12']
+        S1: ['ND', 'VH', 'VV']
+        S2: ['B8', 'B11', 'B12'] #['B4', 'B8', 'B12']
+        # S2: ['B3', 'B8', 'B12'] #['B4', 'B8', 'B12']
 
-    useDataWoCAug: False
-    SEED: 42
-    random_state: 42
+    # REF_MASK: poly
+    TRAIN_MASK: poly
+    TEST_MASK: poly
+    TRAIN_RATIO: 0.9
+    AUGMENT: False
 
-    CLASSES: ['burned']
-    REF_MASK: poly
-    
-    USE_PRE_IMG: True
+MODEL:
+    DEBUG: True
+
+    ARCH: UNet #UNet_resnet18 #FuseUNet, UNet
+    USE_DECONV: True
+    TOPO: [16, 32, 64, 128]
+    LOSS_TYPE: DiceLoss # DiceLoss
+    NUM_CLASSES: 1
+    ACTIVATION: sigmoid #sigmoid
 
-model:
-    ARCH: UNet #FuseUNet, UNet
-    ACTIVATION: sigmoid
     ENCODER: resnet18 # 'mobilenet_v2'
+    ENCODER_DEPTH: 4
     ENCODER_WEIGHTS: imagenet
 
-    max_epoch: 20
-    batch_size: 64
-    learning_rate: 1e-4
-    weight_decay: 1e-4
-    cross_domain_coef: 0
+    MAX_EPOCH: 100
+    BATCH_SIZE: 16
 
-    use_lr_scheduler: True
-    warmup_coef: 2
+    LEARNING_RATE: 1e-4
+    WEIGHT_DECAY: 1e-2
+    LR_SCHEDULER:  poly # ['cosine', 'poly']
+    POLY_SCHEDULER:
+        END_LR: 1e-5
+        POWER: 0.9
+    COSINE_SCHEDULER:
+        WARMUP: 10
     
-    max_score: 0.1 # If IoU > max_score, save model
-    verbose: True
+    MAX_SCORE: 0.1 # If IoU > max_score, save model
+    SAVE_INTERVAL: 5 # save model frequency
+    STEP_WISE_LOG: False # log metrics every step/update
+    VERBOSE: True
 
-eval:
-    patchsize: 512
+EVAL:
+    PATCHSIZE: 512
 
-experiment:
-    note: ${data.satellites}_to_Kam_prg
-    name: ${data.name}_${model.ARCH}_${model.ENCODER}_${experiment.note}
-    output: ./outputs/run_${experiment.name}_${now:%Y%m%dT%H%M%S} #${defaults.0.data}
+EXP:
+    NOTE: prg-debug
+    NAME: ${DATA.NAME}_${MODEL.ARCH}_${DATA.SATELLITES}_${EXP.NOTE}
+    OUTPUT: ./outputs/run_${EXP.NAME}_${now:%Y%m%dT%H%M%S} #${defaults.0.data}
 
 hydra:
     run:
-        dir: ${experiment.output}
\ No newline at end of file
+        dir: ${EXP.OUTPUT}
\ No newline at end of file
diff --git a/config/siam_unet.yaml b/config/siam_unet.yaml
index 14a5fc9..96085d6 100644
--- a/config/siam_unet.yaml
+++ b/config/siam_unet.yaml
@@ -16,7 +16,7 @@ DATA:
     # DIR: /cephyr/NOBACKUP/groups/snic2021-7-104/wildfire-s1s2-dataset-ak-tiles
     # DIR: /cephyr/NOBACKUP/groups/snic2021-7-104/wildfire-s1s2-dataset-ca-tiles
 
-    SATELLITES: ['S1']
+    SATELLITES: ['S1','S2']
     PREPOST: ['pre','post']
     STACKING: True # stack bi-temporal data
 
@@ -28,16 +28,18 @@ DATA:
     INPUT_BANDS:
         ALOS: ['ND', 'VH', 'VV']
         S1: ['ND', 'VH', 'VV']
-        S2: ['B2', 'B3', 'B4', 'B8', 'B11', 'B12'] #['B4', 'B8', 'B12']
+        S2: ['B3','B8', 'B12'] #['B4', 'B8', 'B12']
         # S2: ['B3', 'B8', 'B12'] #['B4', 'B8', 'B12']
 
-    REF_MASK: poly
+    TRAIN_MASK: poly
+    TEST_MASK: poly
     TRAIN_RATIO: 0.9
+    AUGMENT: False
 
 MODEL:
     DEBUG: True
 
-    ARCH: SiamUnet_conc #Paddle_unet #FuseUNet #FuseUNet, UNet
+    ARCH: DualUnet_LF #Paddle_unet #FuseUNet #FuseUNet, UNet
     SHARE_ENCODER: True
 
     TOPO: [16, 32, 64, 128]
diff --git a/config/unet.yaml b/config/unet.yaml
index 00dd3e9..2d9c737 100644
--- a/config/unet.yaml
+++ b/config/unet.yaml
@@ -16,8 +16,8 @@ DATA:
     # DIR: /cephyr/NOBACKUP/groups/snic2021-7-104/wildfire-s1s2-dataset-ak-tiles
     # DIR: /cephyr/NOBACKUP/groups/snic2021-7-104/wildfire-s1s2-dataset-ca-tiles
 
-    SATELLITES: ['S1']
-    PREPOST: ['pre','post']
+    SATELLITES: ['S2']
+    PREPOST: ['pre', 'post']
     STACKING: True # stack bi-temporal data
 
     ALL_BANDS:
@@ -28,37 +28,47 @@ DATA:
     INPUT_BANDS:
         ALOS: ['ND', 'VH', 'VV']
         S1: ['ND', 'VH', 'VV']
-        S2: ['B2', 'B3', 'B4', 'B8', 'B11', 'B12'] #['B4', 'B8', 'B12']
+        S2: ['B4', 'B8', 'B12'] #['B4', 'B8', 'B12']
         # S2: ['B3', 'B8', 'B12'] #['B4', 'B8', 'B12']
 
-    REF_MASK: poly
+    # REF_MASK: poly
+    TRAIN_MASK: poly
+    TEST_MASK: poly
     TRAIN_RATIO: 0.9
+    AUGMENT: False
 
 MODEL:
     DEBUG: True
 
-    ARCH: UNet_resnet18 #FuseUNet, UNet
+    ARCH: UNet #UNet_resnet18 #FuseUNet, UNet
     USE_DECONV: True
     TOPO: [16, 32, 64, 128]
-    LOSS_TYPE: DiceLoss # DiceLoss
-    NUM_CLASSES: 1
-    ACTIVATION: sigmoid #sigmoid
+
+    # LOSS_TYPE: DiceLoss # DiceLoss
+    # NUM_CLASSES: 1
+    # ACTIVATION: sigmoid #sigmoid
+
+    LOSS_TYPE: CrossEntropyLoss # DiceLoss
+    NUM_CLASSES: 2
+    CLASS_NAMES: ['unburn', 'burned']
+    CLASS_WEIGHTS: [0.5, 0.5]
+    ACTIVATION: softmax #sigmoid
 
     ENCODER: resnet18 # 'mobilenet_v2'
     ENCODER_DEPTH: 4
-    ENCODER_WEIGHTS: null
+    ENCODER_WEIGHTS: imagenet
 
     MAX_EPOCH: 100
     BATCH_SIZE: 16
 
     LEARNING_RATE: 1e-4
-    WEIGHT_DECAY: 1e-3
+    WEIGHT_DECAY: 1e-2
     LR_SCHEDULER:  poly # ['cosine', 'poly']
     POLY_SCHEDULER:
         END_LR: 1e-5
         POWER: 0.9
     COSINE_SCHEDULER:
-        WARMUP: 2
+        WARMUP: 10
     
     MAX_SCORE: 0.1 # If IoU > max_score, save model
     SAVE_INTERVAL: 5 # save model frequency
@@ -69,9 +79,10 @@ EVAL:
     PATCHSIZE: 512
 
 EXP:
+    FOLDER: outputs
     NOTE: debug
-    NAME: ${DATA.NAME}_${MODEL.ARCH}_${DATA.SATELLITES}_${EXP.NOTE}
-    OUTPUT: ./outputs/run_${EXP.NAME}_${now:%Y%m%dT%H%M%S} #${defaults.0.data}
+    NAME: ${DATA.TRAIN_MASK}_${MODEL.ARCH}_${DATA.SATELLITES}_${EXP.NOTE}
+    OUTPUT: ./${EXP.FOLDER}/run_${EXP.NAME}_${now:%Y%m%dT%H%M%S} #${defaults.0.data}
 
 hydra:
     run:
diff --git a/dataset/augument.py b/dataset/augument.py
index aa04909..3513aaa 100644
--- a/dataset/augument.py
+++ b/dataset/augument.py
@@ -1,4 +1,6 @@
+from operator import index
 import albumentations as albu
+from matplotlib import transforms
 
 def get_training_augmentation():
     train_transform = [
@@ -69,4 +71,95 @@ def get_preprocessing(preprocessing_fn):
         albu.Lambda(image=preprocessing_fn),
         albu.Lambda(image=to_tensor, mask=to_tensor),
     ]
-    return albu.Compose(_transform)
\ No newline at end of file
+    return albu.Compose(_transform)
+
+
+
+
+import torchvision.transforms as T
+import matplotlib.pyplot as plt
+
+def augment_data(imgs):
+    '''
+    imgs: list of array
+    '''
+    inputs = torch.cat(imgs, dim=0)
+    channels_list = [im.shape[0] for im in imgs]
+    idxs = [np.sum(np.array(channels_list[:i+1])) for i in range(0,len(channels_list))]
+    idxs = [0] + idxs
+
+    _transforms = T.Compose([
+        T.RandomVerticalFlip(p=0.5),
+        T.RandomHorizontalFlip(p=0.5),
+        T.RandomRotation(degrees=270),
+        T.RandomResizedCrop(size=(256,256), scale=(0.2,1), interpolation=T.InterpolationMode.NEAREST),
+        # T.ToTensor()
+    ])
+
+    input_aug = _transforms(inputs)
+    outputs = [input_aug[idxs[i]:idxs[i+1]] for i in range(len(imgs))]
+    return outputs
+
+
+if __name__ == "__main__":
+
+    from pathlib import Path
+    import os
+    import tifffile as tiff
+    import torch
+    import numpy as np
+
+    train_dir = Path('/home/p/u/puzhao/wildfire-s1s2-dataset-ca-tiles') / "test"
+    fileList = os.listdir(train_dir / "mask" / "poly")
+    
+    filename = fileList[400]
+
+    im1 = tiff.imread(train_dir / "S2" / "pre" / f"{filename}")[[5,3,2],] 
+    im2 = tiff.imread(train_dir / "S2" / "post" / f"{filename}")[[5,3,2],] 
+    mask = tiff.imread(train_dir / "mask" / "poly" / f"{filename}")
+
+    # mean=[0.485, 0.456, 0.406],
+    # std=[0.229, 0.224, 0.225]
+
+    im1 = np.nan_to_num(im1, 0)
+    im2 = np.nan_to_num(im2, 0)
+
+    min, max = im2.min(), im2.max()
+    im1 = (im1 - min) / (max - min)
+    im2 = (im2 - min) / (max - min)
+
+
+    # plt.imsave("aug_org.png", im1.transpose(1,2,0))
+
+    im1 = torch.from_numpy(im1)
+    im2 = torch.from_numpy(im2)
+    mask = torch.from_numpy(mask[np.newaxis,])
+
+    imgs = [im1, im2, mask]
+
+    # imgs = [(im*255).type(torch.uint8) for im in imgs]
+
+    outputs = augment_data(imgs)
+    print(type(outputs[0]))
+    print(len(fileList))
+    # print(np.sum((im1_ - im2_).type(torch.float16)))
+
+    # print(im1_.shape, mask_.shape)
+    # print(im1_ - mask_)
+
+    cnt = 0
+    fig, axs = plt.subplots(nrows=len(imgs), ncols=2, constrained_layout=True)
+    for i in range(len(imgs)):
+        img = imgs[i]
+        img_ = outputs[i]
+
+        if len(img.shape) >= 3:
+            axs[i,0].imshow(img.numpy().transpose(1,2,0))
+            axs[i,1].imshow(img_.numpy().transpose(1,2,0))
+        else:
+            axs[i,0].imshow(img.numpy())
+            axs[i,1].imshow(img_.numpy())
+
+    plt.savefig("aug.png")
+
+    print(np.unique(im1))
\ No newline at end of file
diff --git a/dataset/wildfire.py b/dataset/wildfire.py
index 7ff57f6..ed76eea 100644
--- a/dataset/wildfire.py
+++ b/dataset/wildfire.py
@@ -9,7 +9,7 @@ from torch.utils.data import Dataset as BaseDataset
 
 
 class S1S2(BaseDataset):
-    """ MTBS Dataset. Read images, apply augmentation and preprocessing transformations.
+    """ S1S2 Dataset. Read images, apply augmentation and preprocessing transformations.
     
     Args:
         images_dir (str): path to images folder
@@ -38,7 +38,11 @@ class S1S2(BaseDataset):
 
         # images_dir
         data_dir = Path(data_dir)
-        masks_dir = data_dir / "mask" / "poly"
+
+        self.phase = os.path.split(data_dir)[-1]
+        self.REF_MASK = cfg.DATA.TEST_MASK if self.phase == "test" else cfg.DATA.TRAIN_MASK
+        masks_dir = data_dir / "mask" / self.REF_MASK
+
         print("data_dir: ", data_dir)
 
         def get_fps(sat):
@@ -95,17 +99,23 @@ class S1S2(BaseDataset):
 
         ''' read mask '''
         mask = tiff.imread(self.masks_fps[i])
+
+        if self.REF_MASK in ['modis', 'firecci']:
+            mask = (mask > 0).astype('float32')
         
-        if 'poly' == self.cfg.DATA.REF_MASK:
-            masks = [(mask == v) for v in self.class_values] # 1~6
-            mask = np.stack(masks, axis=0).astype('float32')
-            image_list.append(mask)
+        # if 'poly' == self.cfg.DATA.REF_MASK:
+        masks = [(mask == v) for v in self.class_values] # 1~6
+        mask = np.stack(masks, axis=0).astype('float32')
+        image_list.append(mask)
+        imgs = [torch.from_numpy(img) for img in image_list]
 
-        # # apply augmentations
-        # if self.augmentation:
-        #     # sample = self.augmentation(image=image, mask=mask)
-        #     # image, mask = sample['image'], sample['mask']
-        #     image_list = [self.augmentation(image=image.transpose(1,2,0))['image'].transpose(2,0,1) for image in image_list]
+        if 'train' == self.phase:
+            if self.cfg.DATA.AUGMENT:
+                imgs_aug = augment_data(imgs)
+                imgs = [torch.cat((x, x_aug), dim=0) for x, x_aug in zip(imgs, imgs_aug)] # # [x,x_aug], [y,y_aug]
+            
+        return (tuple(imgs[:-1]), imgs[-1]) # x, y
+        
         
         # # apply preprocessing
         # if self.preprocessing:
@@ -114,7 +124,8 @@ class S1S2(BaseDataset):
         #     image_list = [self.preprocessing(image=image.transpose(1,2,0))['image'].transpose(2,0,1) for image in image_list]
 
         # return tuple(image_list)
-        return (tuple(image_list[:-1]), image_list[-1])
+        # return (tuple(image_list[:-1]), image_list[-1])
+        
         
     def __len__(self):
         return len(self.ids)
@@ -126,11 +137,7 @@ class S1S2(BaseDataset):
         def get_band_index(sat):
             all_bands = list(ALL_BANDS[sat])
             input_bands = list(INPUT_BANDS[sat])
-
-            band_index = []
-            for band in input_bands:
-                band_index.append(all_bands.index(band))
-            return band_index
+            return [all_bands.index(band) for band in input_bands]
 
         band_index_dict = {}
         for sat in ['ALOS', 'S1', 'S2']:
@@ -141,6 +148,32 @@ class S1S2(BaseDataset):
     def normalize_sar(self, img):
         return (np.clip(img, -30, 0) + 30) / 30
 
+
+''' Data Augments '''
+import torch
+import torchvision.transforms as T
+
+def augment_data(imgs):
+    '''
+    imgs: list of array
+    '''
+    inputs = torch.cat(imgs, dim=0)
+    channels_list = [im.shape[0] for im in imgs]
+    idxs = [np.sum(np.array(channels_list[:i+1])) for i in range(0,len(channels_list))]
+    idxs = [0] + idxs
+
+    _transforms = T.Compose([
+        T.RandomVerticalFlip(p=0.5),
+        T.RandomHorizontalFlip(p=0.5),
+        T.RandomRotation(degrees=270),
+        T.RandomResizedCrop(size=(256,256), scale=(0.2,1), interpolation=T.InterpolationMode.NEAREST),
+        # T.ToTensor()
+    ])
+
+    input_aug = _transforms(inputs)
+    outputs = [input_aug[idxs[i]:idxs[i+1]] for i in range(len(imgs))]
+    return outputs
+
 class MTBS(BaseDataset):
     """ MTBS Dataset. Read images, apply augmentation and preprocessing transformations.
     
@@ -155,28 +188,45 @@ class MTBS(BaseDataset):
     
     """
     
-    CLASSES = ['bgd', 'unburn', 'low', 'moderate', 'high', 'greener', 'cloud']
+    CLASSES = ['unburn', 'low', 'moderate', 'high'] # 'greener', 'cloud'
     
     def __init__(
             self, 
-            images_dir, 
-            masks_dir, 
+            data_dir, 
+            cfg, 
             classes=None, 
             augmentation=None, 
             preprocessing=None,
     ):
+        self.cfg = cfg
+        self.band_index_dict = self.get_band_index_dict()
+        print(self.band_index_dict)
+
         # images_dir
-        images_dir = Path(images_dir)
+        data_dir = Path(data_dir)
+
+        self.phase = os.path.split(data_dir)[-1]
+        self.REF_MASK = cfg.DATA.TEST_MASK if self.phase == "test" else cfg.DATA.TRAIN_MASK
+        masks_dir = data_dir / "mask" / self.REF_MASK
+
+        print("data_dir: ", data_dir)
 
-        # image and mask dir
-        pre_dir = images_dir / "pre"
-        post_dir = images_dir / "post"
-        masks_dir = images_dir / "mask"
+        def get_fps(sat):
+            # image and mask dir
+            pre_dir = data_dir / sat / "pre"
+            post_dir = data_dir / sat / "post"
+            
+            # fps
+            ids = sorted(os.listdir(post_dir)) # modified on Jan-09
+            pre_fps = [os.path.join(pre_dir, image_id) for image_id in ids]
+            post_fps = [os.path.join(post_dir, image_id) for image_id in ids]
+            return pre_fps, post_fps, ids
 
-        # fps
-        self.ids = os.listdir(pre_dir)
-        self.pre_fps = [os.path.join(pre_dir, image_id) for image_id in self.ids]
-        self.post_fps = [os.path.join(post_dir, image_id) for image_id in self.ids]
+        self.fps_dict = {}
+        for sat in self.cfg.DATA.SATELLITES:
+            self.fps_dict[sat] = get_fps(sat)
+        # self.ids = self.fps_dict[sat][-1]
+        self.ids = sorted(self.fps_dict[self.cfg.DATA.SATELLITES[0]][-1])
         self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]
         
         # convert str names to class values on masks
@@ -188,37 +238,86 @@ class MTBS(BaseDataset):
     
     def __getitem__(self, i):
         
-        # read data
-        image_pre = tiff.imread(self.pre_fps[i])
-        image_post = tiff.imread(self.post_fps[i])
+        ''' read data '''
+        image_list = []
+        # for sat in sorted(self.fps_dict.keys()):
+        for sat in self.cfg.DATA.SATELLITES: # modified on Jan-9
+            post_fps = self.fps_dict[sat][1]
+            image_post = tiff.imread(post_fps[i]) # C*H*W
+            image_post = np.nan_to_num(image_post, 0)
+            if sat in ['S1','ALOS']: image_post = self.normalize_sar(image_post)
+            image_post = image_post[self.band_index_dict[sat],] # select bands
 
-        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
-        image = np.concatenate((image_pre, image_post), axis=0)
-        # image = image.transpose(1,2,0)
+            if 'pre' in self.cfg.DATA.PREPOST:
+                pre_fps = self.fps_dict[sat][0]
+                image_pre = tiff.imread(pre_fps[i])
+                image_pre = np.nan_to_num(image_pre, 0)
+                if sat in ['S1','ALOS']: image_pre = self.normalize_sar(image_pre)
+                image_pre = image_pre[self.band_index_dict[sat],] # select bands
+                
+                if self.cfg.DATA.STACKING: # if stacking bi-temporal data
+                    stacked = np.concatenate((image_pre, image_post), axis=0) 
+                    image_list.append(stacked) #[x1, x2]
+                else:
+                    image_list += [image_pre, image_post] #[t1, t2]
+            else:
+                image_list.append(image_post) #[x1_t2, x2_t2]
+
+        ''' read mask '''
         mask = tiff.imread(self.masks_fps[i])
-        mask[mask==0] = 1 # set background as unburned 1, added by Puzhao on June 2
-        mask = mask.astype(float) - 1
-                        
-        # # extract certain classes from mask (e.g. cars)
-        # masks = [(mask == v) for v in self.class_values] # 1~6
-        # # mask = np.stack(masks, axis=-1).astype('float')
-        # mask = np.stack(masks, axis=0).astype('float') # modified by puzhao on June 1st, 2021
-        
-        # apply augmentations
-        if self.augmentation:
-            sample = self.augmentation(image=image, mask=mask)
-            image, mask = sample['image'], sample['mask']
-        
-        # apply preprocessing
-        if self.preprocessing:
-            sample = self.preprocessing(image=image, mask=mask)
-            image, mask = sample['image'], sample['mask']
+
+        if self.REF_MASK in ['modis', 'firecci']:
+            mask = (mask > 0).astype('float32')
+
+        if 'mtbs' == self.REF_MASK:
+            mask[mask==0] = 1 # both 0 and 1 are unburned
+            mask[mask>=5] = 0 # ignore 'greener' (5), 'cloud' (6)
+            mask = mask - 1 # 4 classes in total: 0, 1, 2, 3
+        else:
+            masks = [(mask == v) for v in self.class_values] # 1~6
+            mask = np.stack(masks, axis=0).astype('float32')
+
+        image_list.append(mask[np.newaxis,])
+        imgs = [torch.from_numpy(img) for img in image_list]
+
+        if 'train' == self.phase:
+            if self.cfg.DATA.AUGMENT:
+                imgs_aug = augment_data(imgs)
+                imgs = [torch.cat((x, x_aug), dim=0) for x, x_aug in zip(imgs, imgs_aug)] # # [x,x_aug], [y,y_aug]
             
-        # return image, mask
-        return image_pre, image_post, mask # edited on Setp. 6
+        return (tuple(imgs[:-1]), imgs[-1]) # x, y
+        
+        
+        # # apply preprocessing
+        # if self.preprocessing:
+        #     # sample = self.preprocessing(image=mask, mask=mask)
+        #     # image, mask = sample['image'], sample['mask']
+        #     image_list = [self.preprocessing(image=image.transpose(1,2,0))['image'].transpose(2,0,1) for image in image_list]
+
+        # return tuple(image_list)
+        # return (tuple(image_list[:-1]), image_list[-1])
+        
         
     def __len__(self):
         return len(self.ids)
 
+    def get_band_index_dict(self):
+        ALL_BANDS = self.cfg.DATA.ALL_BANDS
+        INPUT_BANDS = self.cfg.DATA.INPUT_BANDS
+
+        def get_band_index(sat):
+            all_bands = list(ALL_BANDS[sat])
+            input_bands = list(INPUT_BANDS[sat])
+            return [all_bands.index(band) for band in input_bands]
+
+        band_index_dict = {}
+        for sat in ['ALOS', 'S1', 'S2']:
+            band_index_dict[sat] = get_band_index(sat)
+        
+        return band_index_dict
+
+    def normalize_sar(self, img):
+        return (np.clip(img, -30, 0) + 30) / 30
+
 
 
Submodule fcnn4cd contains untracked content
Submodule fcnn4cd contains modified content
diff --git a/fcnn4cd/.gitignore b/fcnn4cd/.gitignore
deleted file mode 100644
index 894a44c..0000000
--- a/fcnn4cd/.gitignore
+++ /dev/null
@@ -1,104 +0,0 @@
-# Byte-compiled / optimized / DLL files
-__pycache__/
-*.py[cod]
-*$py.class
-
-# C extensions
-*.so
-
-# Distribution / packaging
-.Python
-build/
-develop-eggs/
-dist/
-downloads/
-eggs/
-.eggs/
-lib/
-lib64/
-parts/
-sdist/
-var/
-wheels/
-*.egg-info/
-.installed.cfg
-*.egg
-MANIFEST
-
-# PyInstaller
-#  Usually these files are written by a python script from a template
-#  before PyInstaller builds the exe, so as to inject date/other infos into it.
-*.manifest
-*.spec
-
-# Installer logs
-pip-log.txt
-pip-delete-this-directory.txt
-
-# Unit test / coverage reports
-htmlcov/
-.tox/
-.coverage
-.coverage.*
-.cache
-nosetests.xml
-coverage.xml
-*.cover
-.hypothesis/
-.pytest_cache/
-
-# Translations
-*.mo
-*.pot
-
-# Django stuff:
-*.log
-local_settings.py
-db.sqlite3
-
-# Flask stuff:
-instance/
-.webassets-cache
-
-# Scrapy stuff:
-.scrapy
-
-# Sphinx documentation
-docs/_build/
-
-# PyBuilder
-target/
-
-# Jupyter Notebook
-.ipynb_checkpoints
-
-# pyenv
-.python-version
-
-# celery beat schedule file
-celerybeat-schedule
-
-# SageMath parsed files
-*.sage.py
-
-# Environments
-.env
-.venv
-env/
-venv/
-ENV/
-env.bak/
-venv.bak/
-
-# Spyder project settings
-.spyderproject
-.spyproject
-
-# Rope project settings
-.ropeproject
-
-# mkdocs documentation
-/site
-
-# mypy
-.mypy_cache/
diff --git a/fcnn4cd/siamunet_conc.py b/fcnn4cd/siamunet_conc.py
index 83ec20c..a3fbc6e 100644
--- a/fcnn4cd/siamunet_conc.py
+++ b/fcnn4cd/siamunet_conc.py
@@ -89,9 +89,11 @@ class SiamUnet_conc(nn.Module):
         self.do12d = nn.Dropout2d(p=0.2)
         self.conv11d = nn.ConvTranspose2d(16, label_nbr, kernel_size=3, padding=1)
 
-        self.sm = nn.LogSoftmax(dim=1)
+        # self.sm = nn.LogSoftmax(dim=1)
+        self.sm = nn.Sigmoid()
 
-    def forward(self, x1, x2):
+    def forward(self, x):
+        x1, x2 = x
 
         """Forward method."""
         # Stage 1
diff --git a/fcnn4cd/siamunet_diff.py b/fcnn4cd/siamunet_diff.py
index eb90957..8a99162 100644
--- a/fcnn4cd/siamunet_diff.py
+++ b/fcnn4cd/siamunet_diff.py
@@ -89,11 +89,11 @@ class SiamUnet_diff(nn.Module):
         self.do12d = nn.Dropout2d(p=0.2)
         self.conv11d = nn.ConvTranspose2d(16, label_nbr, kernel_size=3, padding=1)
 
-        self.sm = nn.LogSoftmax(dim=1)
-
-    def forward(self, x1, x2):
-
+        # self.sm = nn.LogSoftmax(dim=1)
+        self.sm = nn.Sigmoid()
 
+    def forward(self, x):
+        x1, x2 = x
         """Forward method."""
         # Stage 1
         x11 = self.do11(F.relu(self.bn11(self.conv11(x1))))
diff --git a/fcnn4cd/unet.py b/fcnn4cd/unet.py
index 1f1721f..b3b98ce 100644
--- a/fcnn4cd/unet.py
+++ b/fcnn4cd/unet.py
@@ -90,11 +90,11 @@ class Unet(nn.Module):
         self.do12d = nn.Dropout2d(p=0.2)
         self.conv11d = nn.ConvTranspose2d(16, label_nbr, kernel_size=3, padding=1)
 
-        self.sm = nn.LogSoftmax(dim=1)
+        # self.sm = nn.LogSoftmax(dim=1)
+        self.sm = nn.Sigmoid()
 
-    def forward(self, x1, x2):
-
-        x = torch.cat((x1, x2), 1)
+    def forward(self, x):
+        x = torch.cat(x, 1)
 
         """Forward method."""
         # Stage 1
@@ -119,7 +119,6 @@ class Unet(nn.Module):
         x43 = self.do43(F.relu(self.bn43(self.conv43(x42))))
         x4p = F.max_pool2d(x43, kernel_size=2, stride=2)
 
-
         # Stage 4d
         x4d = self.upconv4(x4p)
         pad4 = ReplicationPad2d((0, x43.size(3) - x4d.size(3), 0, x43.size(2) - x4d.size(2)))
@@ -153,3 +152,10 @@ class Unet(nn.Module):
         return self.sm(x11d)
 
     
+if __name__ == "__main__":
+
+    import numpy as np
+    from torchsummary import summary
+
+    myunet = Unet(input_nbr=3, label_nbr=2)
+    # summary(myunet, (3,256,256))
\ No newline at end of file
diff --git a/log_test/1429_submitted.pkl b/log_test/1429_submitted.pkl
deleted file mode 100644
index f236294..0000000
Binary files a/log_test/1429_submitted.pkl and /dev/null differ
diff --git a/main_s1s2_unet copy.py b/main_s1s2_unet copy.py
deleted file mode 100644
index 3662b4e..0000000
--- a/main_s1s2_unet copy.py	
+++ /dev/null
@@ -1,403 +0,0 @@
-# checkpoint: https://github.com/pytorch/examples/blob/42e5b996718797e45c46a25c55b031e6768f8440/imagenet/main.py#L89-L101
-
-import os, json
-import random
-from easydict import EasyDict as edict
-from pathlib import Path
-from prettyprinter import pprint
-from imageio import imread, imsave
-
-import hydra
-import wandb
-from omegaconf import DictConfig, OmegaConf
-
-
-###################################################################################
-import os, sys
-import numpy as np
-from pathlib import Path
-import hydra
-from omegaconf import DictConfig, OmegaConf
-
-import copy
-import time
-import torch
-
-import torch.optim as optim
-import torch.nn as nn
-import torch.nn.functional as F
-from easydict import EasyDict as edict
-
-from tqdm import tqdm as tqdm
-
-import logging
-logger = logging.getLogger(__name__)
-
-import smp
-from smp.base.modules import Activation
-from models.model_selection import get_model
-import wandb
-
-# f_score = smp.utils.functional.f_score
-# Dice/F1 score - https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient
-# IoU/Jaccard score - https://en.wikipedia.org/wiki/Jaccard_index
-# diceLoss = smp.utils.losses.DiceLoss(eps=1)
-from models.loss_ref import soft_dice_loss, soft_dice_loss_balanced, jaccard_like_loss, jaccard_like_balanced_loss
-
-AverageValueMeter =  smp.utils.train.AverageValueMeter
-
-# Augmentations
-from dataset.augument import get_training_augmentation, \
-    get_validation_augmentation, get_preprocessing
-
-from torch.utils.data import DataLoader
-from dataset.wildfire import S1S2 as Dataset # ------------------------------------------------------- Dataset
-
-from models.lr_schedule import get_cosine_schedule_with_warmup, PolynomialLRDecay
-
-
-def format_logs(logs):
-    str_logs = ['{}: {:.4}'.format(k, v) for k, v in logs.items()]
-    s = ', '.join(str_logs)
-    return s
-
-
-def loss_fun(CFG, DEVICE='cuda'):
-    if CFG.MODEL.LOSS_TYPE == 'BCELoss':
-        criterion = nn.BCELoss()
-
-    elif CFG.MODEL.LOSS_TYPE == 'BCEWithLogitsLoss':
-        criterion = nn.BCEWithLogitsLoss() # includes sigmoid activation
-
-    elif CFG.MODEL.LOSS_TYPE == 'DiceLoss':
-        criterion = smp.utils.losses.DiceLoss(eps=1, activation=CFG.MODEL.ACTIVATION)
-
-    elif CFG.MODEL.LOSS_TYPE == 'CrossEntropyLoss':
-        balance_weight = [CFG.MODEL.NEGATIVE_WEIGHT, CFG.MODEL.POSITIVE_WEIGHT]
-        balance_weight = torch.tensor(balance_weight).float().to(DEVICE)
-        criterion = nn.CrossEntropyLoss(weight = balance_weight)
-        
-    elif CFG.MODEL.LOSS_TYPE == 'SoftDiceLoss':
-        criterion = soft_dice_loss 
-    elif CFG.MODEL.LOSS_TYPE == 'SoftDiceBalancedLoss':
-        criterion = soft_dice_loss_balanced
-    elif CFG.MODEL.LOSS_TYPE == 'JaccardLikeLoss':
-        criterion = jaccard_like_loss
-    elif CFG.MODEL.LOSS_TYPE == 'ComboLoss':
-        criterion = lambda pred, gts: F.binary_cross_entropy_with_logits(pred, gts) + soft_dice_loss(pred, gts)
-    elif CFG.MODEL.LOSS_TYPE == 'WeightedComboLoss':
-        criterion = lambda pred, gts: F.binary_cross_entropy_with_logits(pred, gts) + 10 * soft_dice_loss(pred, gts)
-    elif CFG.MODEL.LOSS_TYPE == 'FrankensteinLoss':
-        criterion = lambda pred, gts: F.binary_cross_entropy_with_logits(pred, gts) + jaccard_like_balanced_loss(pred, gts)
-
-    return criterion
-
-class SegModel(object):
-    def __init__(self, cfg) -> None:
-        super().__init__()
-        self.PROJECT_DIR = Path(hydra.utils.get_original_cwd())
-
-        self.cfg = cfg
-        self.DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
-        # self.DEVICE = 'cpu'
-
-        self.model = get_model(cfg)
-        self.activation = Activation(self.cfg.MODEL.ACTIVATION)
-
-        # self.MODEL_URL = str(self.PROJECT_DIR / "outputs" / "best_model.pth")
-        self.RUN_DIR = self.PROJECT_DIR / self.cfg.EXP.OUTPUT
-        self.MODEL_URL = str(self.RUN_DIR / "model.pth")
-
-        # if CFG.MODEL.ENCODER is not None:
-        #     self.preprocessing_fn = \
-        #         smp.encoders.get_preprocessing_fn(CFG.MODEL.ENCODER, CFG.MODEL.ENCODER_WEIGHTS)
-
-        self.metrics = [smp.utils.metrics.IoU(threshold=0.5, activation=None),
-                        smp.utils.metrics.Fscore(activation=None)
-                    ]
-
-        '''--------------> need to improve <-----------------'''
-        # specify data folder
-        self.TRAIN_DIR = Path(self.cfg.DATA.DIR) / 'train'
-        self.VALID_DIR = Path(self.cfg.DATA.DIR) / 'test'
-        '''--------------------------------------------------'''
-    
-    def get_dataloaders(self) -> dict:
-
-        if self.cfg.MODEL.NUM_CLASSES == 1:
-            classes = ['burned']
-        elif self.cfg.MODEL.NUM_CLASSES == 2:
-            classes = ['unburn', 'burned']
-        elif self.cfg.MODEL.NUM_CLASSES > 2:
-            print(" ONLY ALLOW ONE or TWO CLASSES SO FAR !!!")
-            pass
-
-        """ Data Preparation """
-        train_dataset = Dataset(
-            self.TRAIN_DIR, 
-            self.cfg, 
-            # augmentation=get_training_augmentation(), 
-            # preprocessing=get_preprocessing(self.preprocessing_fn),
-            classes=classes,
-        )
-
-        valid_dataset = Dataset(
-            self.VALID_DIR, 
-            self.cfg, 
-            # augmentation=get_validation_augmentation(), 
-            # preprocessing=get_preprocessing(self.preprocessing_fn),
-            classes=classes,
-        )
-
-        generator=torch.Generator().manual_seed(self.cfg.RAND.SEED)
-        train_size = int(len(train_dataset) * self.cfg.DATA.TRAIN_RATIO)
-        valid_size = len(train_dataset) - train_size
-        train_set, val_set = torch.utils.data.random_split(train_dataset, [train_size, valid_size], generator=generator)
-
-        train_loader = DataLoader(train_set, batch_size=self.cfg.MODEL.BATCH_SIZE, shuffle=True, num_workers=4, generator=generator)
-        valid_loader = DataLoader(val_set, batch_size=self.cfg.MODEL.BATCH_SIZE, shuffle=True, num_workers=4, generator=generator)
-        test_loader = DataLoader(valid_dataset, batch_size=self.cfg.MODEL.BATCH_SIZE, shuffle=True, num_workers=4, generator=generator)
-
-# means = []
-# stds = []
-# for img in list(iter(train_loader)):
-#     print(img.shape)
-#     means.append(torch.mean(img))
-#     stds.append(torch.std(img))
-
-# mean = torch.mean(torch.tensor(means))
-# std = torch.mean(torch.tensor(stds))
-        
-        dataloaders = { 
-                        'train': train_loader, \
-                        'valid': valid_loader, \
-                        'test': test_loader, \
-
-                        'train_size': train_size, \
-                        'valid_size': valid_size, \
-                        'test_size': len(valid_dataset)
-                    }
-
-        return dataloaders
-
-
-    def run(self) -> None:
-        self.model.to(self.DEVICE)
-        self.criterion = loss_fun(self.cfg)
-
-        self.dataloaders = self.get_dataloaders()
-        self.optimizer = torch.optim.Adam([dict(
-                params=self.model.parameters(), 
-                lr=self.cfg.MODEL.LEARNING_RATE, 
-                weight_decay=self.cfg.MODEL.WEIGHT_DECAY)])
-
-        """ ===================== >> learning rate scheduler << ========================= """
-        per_epoch_steps = self.dataloaders['train_size'] // self.cfg.MODEL.BATCH_SIZE
-        total_training_steps = self.cfg.MODEL.MAX_EPOCH * per_epoch_steps
-
-        self.USE_LR_SCHEDULER = True \
-            if self.cfg.MODEL.LR_SCHEDULER in ['cosine_warmup', 'polynomial'] \
-            else True
-
-        if self.cfg.MODEL.LR_SCHEDULER == 'cosine':
-            ''' cosine scheduler '''
-            warmup_steps = self.cfg.MODEL.COSINE_SCHEDULER.WARMUP * per_epoch_steps
-            self.lr_scheduler = get_cosine_schedule_with_warmup(self.optimizer, warmup_steps, total_training_steps)
-
-        elif self.cfg.MODEL.LR_SCHEDULER == 'poly':
-            ''' polynomial '''
-            self.lr_scheduler = PolynomialLRDecay(self.optimizer, 
-                            max_decay_steps=total_training_steps, 
-                            end_learning_rate=self.cfg.MODEL.POLY_SCHEDULER.END_LR, #1e-5, 
-                            power=self.cfg.MODEL.POLY_SCHEDULER.POWER, #0.9
-                        )
-        else:
-            pass
-
-
-        # self.history_logs = edict()
-        # self.history_logs['train'] = []
-        # self.history_logs['valid'] = []
-        # self.history_logs['test'] = []
-
-        # --------------------------------- Train -------------------------------------------
-        max_score = self.cfg.MODEL.MAX_SCORE
-        self.iters = 0
-        for epoch in range(0, self.cfg.MODEL.MAX_EPOCH):
-            epoch = epoch + 1
-            print(f"\n==> train epoch: {epoch}/{self.cfg.MODEL.MAX_EPOCH}")
-            self.train_one_epoch(epoch)
-            valid_logs = self.valid_logs
-            
-            # do something (save model, change lr, etc.)
-            if valid_logs['iou_score'] > max_score:
-                max_score = valid_logs['iou_score']
-
-                if (1 == epoch) or (0 == (epoch % self.cfg.MODEL.SAVE_INTERVAL)):
-                    torch.save(self.model, self.MODEL_URL)
-                    # torch.save(self.model.state_dict(), self.MODEL_URL)
-                    print('Model saved!')
-
-            # if epoch % 50 == 0:
-            #     self.optimizer.param_groups[0]['lr'] = 0.1 * self.optimizer.param_groups[0]['lr']
-                        
-        
-    def train_one_epoch(self, epoch):
-    
-        # wandb.
-        for phase in ['train', 'valid', 'test']:
-            if phase == 'train':
-                self.model.train()
-            else:
-                self.model.eval()
-
-            logs = self.step(phase) 
-            # print(phase, logs)
-
-            currlr = self.optimizer.param_groups[0]['lr'] 
-            wandb.log({phase: logs, 'epoch': epoch, 'lr': currlr})
-
-            # temp = [logs["total_loss"]] + [logs[self.metrics[i].__name__] for i in range(0, len(self.metrics))]
-            # self.history_logs[phase].append(temp)
-
-            if phase == 'valid': self.valid_logs = logs
-
-
-    def step(self, phase) -> dict:
-        logs = {}
-        loss_meter = AverageValueMeter()
-        metrics_meters = {metric.__name__: AverageValueMeter() for metric in self.metrics}
-
-        # if ('Train' in phase) and (self.cfg.useDataWoCAug):
-        #     dataLoader_woCAug = iter(self.dataloaders['Train_woCAug'])
-
-        with tqdm(iter(self.dataloaders[phase]), desc=phase, file=sys.stdout, disable=not self.cfg.MODEL.VERBOSE) as iterator:
-            for i, (x, y) in enumerate(iterator):
-                self.optimizer.zero_grad()
-
-                ''' move data to GPU '''
-                input = []
-                for x_ in x: input.append(x_.to(self.DEVICE))
-                y = y.to(self.DEVICE)
-                # print(len(input))
-
-                ''' do prediction '''
-                if 'UNet_resnet' in self.cfg.MODEL.ARCH: 
-                    input = input[0]
-                    out = self.model.forward(input)
-                else:
-                    out = self.model.forward(input)[-1]
-                y_pred = self.activation(out) # If use this, set IoU/F1 metrics activation=None
-
-                ''' compute loss '''
-                loss_ = self.criterion(out, y)
-
-                ''' Back Propergation (BP) '''
-                if phase == 'train':
-                    loss_.backward()
-                    self.optimizer.step()
-                    self.iters = self.iters + 1
-
-                    ''' Iteration-Wise log for train stage only '''
-                    if self.cfg.MODEL.STEP_WISE_LOG:
-                        self.iters = self.iters + 1
-                        currlr = self.optimizer.param_groups[0]['lr'] 
-                        # wandb.log({'x0.mean': x[0].mean()})
-                        wandb.log({phase: logs, 'iters': self.iters, 'lr': currlr})
-
-                    if self.USE_LR_SCHEDULER:
-                        self.lr_scheduler.step()
-
-                # if mask is in one-hot: NCWH, C=NUM_CLASSES (C>1), and do nothing if C=1
-                if y.shape[1] >= 2: 
-                    y = self.activation(y)
-
-                ''' update loss and metrics logs '''
-                # update loss logs
-                loss_value = loss_.cpu().detach().numpy()
-                loss_meter.add(loss_value)
-                # loss_logs = {criterion.__name__: loss_meter.mean}
-                loss_logs = {'total_loss': loss_meter.mean}
-                logs.update(loss_logs)
-
-                # update metrics logs
-                for metric_fn in self.metrics:
-                    metric_value = metric_fn(y_pred, y).cpu().detach().numpy()
-                    metrics_meters[metric_fn.__name__].add(metric_value)
-
-                metrics_logs = {k: v.mean for k, v in metrics_meters.items()}
-                logs.update(metrics_logs)
-                # print(self.iters, x[0].mean().item(), loss_.item())
-
-                if self.cfg.MODEL.VERBOSE:
-                    s = format_logs(logs)
-                    iterator.set_postfix_str(s)
-
-        return logs
-##############################################################
-
-
-def set_random_seed(seed, deterministic=False):
-    """Set random seed.
-
-    Args:
-        seed (int): Seed to be used.
-        deterministic (bool): Whether to set the deterministic option for
-            CUDNN backend, i.e., set `torch.backends.cudnn.deterministic`
-            to True and `torch.backends.cudnn.benchmark` to False.
-            Default: False.
-    """
-    random.seed(seed)
-    np.random.seed(seed)
-    torch.manual_seed(seed)
-    torch.cuda.manual_seed_all(seed)
-    if deterministic:
-        torch.backends.cudnn.deterministic = True
-        torch.backends.cudnn.benchmark = False
-
-
-@hydra.main(config_path="./config", config_name="unet")
-def run_app(cfg : DictConfig) -> None:
-
-    ''' set randome seed '''
-    os.environ['HYDRA_FULL_ERROR'] = str(1)
-    os.environ['PYTHONHASHSEED'] = str(cfg.RAND.SEED) #cfg.RAND.SEED
-    if cfg.RAND.DETERMIN:
-        os.environ['CUBLAS_WORKSPACE_CONFIG']=":4096:8" #https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility
-        torch.use_deterministic_algorithms(True)
-    set_random_seed(cfg.RAND.SEED, deterministic=cfg.RAND.DETERMIN)
-
-    # wandb.init(config=cfg, project=cfg.project.name, name=cfg.EXP.name)
-    import pandas as pd
-    from prettyprinter import pprint
-    
-    cfg_dict = OmegaConf.to_container(cfg, resolve=True)
-    cfg_flat = pd.json_normalize(cfg_dict, sep='.').to_dict(orient='records')[0]
-
-    # cfg.MODEL.DEBUG = False
-    # if not cfg.MODEL.DEBUG:
-    wandb.init(config=cfg_flat, project=cfg.PROJECT.NAME, entity=cfg.PROJECT.ENTITY, name=cfg.EXP.NAME)
-    pprint(cfg_flat)
-
-    ''' train '''
-    # from experiments.seg_model import SegModel
-    mySegModel = SegModel(cfg)
-    mySegModel.run()
-
-    ''' inference '''
-    from s1s2_evaluator import evaluate_model
-    evaluate_model(cfg, mySegModel.MODEL_URL, mySegModel.RUN_DIR / "errMap")
-
-    ''' compute IoU and F1 for all events '''
-    from utils.iou4all import compute_IoU_F1
-    compute_IoU_F1(phase="test_images", 
-                    result_dir=mySegModel.RUN_DIR / "errMap", 
-                    dataset_dir=cfg.DATA.DIR)
-    
-    # if not cfg.MODEL.DEBUG:
-    wandb.finish()
-
-
-if __name__ == "__main__":
-
-    run_app()
diff --git a/main_s1s2_unet.py b/main_s1s2_unet.py
index b2b7cbe..35a5f6f 100644
--- a/main_s1s2_unet.py
+++ b/main_s1s2_unet.py
@@ -73,9 +73,14 @@ def loss_fun(CFG, DEVICE='cuda'):
         criterion = smp.utils.losses.DiceLoss(eps=1, activation=CFG.MODEL.ACTIVATION)
 
     elif CFG.MODEL.LOSS_TYPE == 'CrossEntropyLoss':
-        balance_weight = [CFG.MODEL.NEGATIVE_WEIGHT, CFG.MODEL.POSITIVE_WEIGHT]
+        # balance_weight = [CFG.MODEL.NEGATIVE_WEIGHT, CFG.MODEL.POSITIVE_WEIGHT]
+        # balance_weight = torch.tensor(balance_weight).float().to(DEVICE)
+        # criterion = nn.CrossEntropyLoss(weight = balance_weight)
+
+        balance_weight = [class_weight for class_weight in CFG.MODEL.CLASS_WEIGHTS]
         balance_weight = torch.tensor(balance_weight).float().to(DEVICE)
-        criterion = nn.CrossEntropyLoss(weight = balance_weight)
+        criterion = nn.CrossEntropyLoss(weight = balance_weight, ignore_index=-1)
+        # criterion = nn.CrossEntropyLoss(ignore_index=-1)
         
     elif CFG.MODEL.LOSS_TYPE == 'SoftDiceLoss':
         criterion = soft_dice_loss 
@@ -124,13 +129,15 @@ class SegModel(object):
     
     def get_dataloaders(self) -> dict:
 
-        if self.cfg.MODEL.NUM_CLASSES == 1:
-            classes = ['burned']
-        elif self.cfg.MODEL.NUM_CLASSES == 2:
-            classes = ['unburn', 'burned']
-        elif self.cfg.MODEL.NUM_CLASSES > 2:
-            print(" ONLY ALLOW ONE or TWO CLASSES SO FAR !!!")
-            pass
+        # if self.cfg.MODEL.NUM_CLASSES == 1:
+        #     classes = ['burned']
+        # elif self.cfg.MODEL.NUM_CLASSES == 2:
+        #     classes = ['unburn', 'burned']
+        # elif self.cfg.MODEL.NUM_CLASSES > 2:
+        #     print(" ONLY ALLOW ONE or TWO CLASSES SO FAR !!!")
+        #     pass
+
+        classes = self.cfg.MODEL.CLASS_NAMES
 
         """ Data Preparation """
         train_dataset = Dataset(
@@ -266,7 +273,8 @@ class SegModel(object):
     def step(self, phase) -> dict:
         logs = {}
         loss_meter = AverageValueMeter()
-        metrics_meters = {metric.__name__: AverageValueMeter() for metric in self.metrics}
+        # metrics_meters = {metric.__name__: AverageValueMeter() for metric in self.metrics}
+        metrics_meters = {f"{metric.__name__}_class{cls}": AverageValueMeter() for metric in self.metrics for cls in range(0, max(2, self.cfg.MODEL.NUM_CLASSES))}
 
         # if ('Train' in phase) and (self.cfg.useDataWoCAug):
         #     dataLoader_woCAug = iter(self.dataloaders['Train_woCAug'])
@@ -278,7 +286,7 @@ class SegModel(object):
                 ''' move data to GPU '''
                 input = []
                 for x_ in x: input.append(x_.to(self.DEVICE))
-                y = y.to(self.DEVICE)
+                y = y.to(self.DEVICE) # BCHW
                 # print(len(input))
 
                 ''' do prediction '''
@@ -287,10 +295,14 @@ class SegModel(object):
                     out = self.model.forward(input)
                 else:
                     out = self.model.forward(input)[-1]
-                y_pred = self.activation(out) # If use this, set IoU/F1 metrics activation=None
 
+                if 'softmax' in self.cfg.MODEL.ACTIVATION:
+                    y_gts = torch.argmax(y, dim=1) # BHW [0, 1, 2, NUM_CLASSES-1]
+                    y_pred = torch.argmax(self.activation(out), dim=1) # BHW
+                
                 ''' compute loss '''
-                loss_ = self.criterion(out, y)
+                # loss_ = self.criterion(out, y) # include activation
+                loss_ = self.criterion(out, y_gts) # Cross Entropy Loss
 
                 ''' Back Propergation (BP) '''
                 if phase == 'train':
@@ -308,9 +320,6 @@ class SegModel(object):
                     if self.USE_LR_SCHEDULER:
                         self.lr_scheduler.step()
 
-                # if mask is in one-hot: NCWH, C=NUM_CLASSES (C>1), and do nothing if C=1
-                if y.shape[1] >= 2: 
-                    y = self.activation(y)
 
                 ''' update loss and metrics logs '''
                 # update loss logs
@@ -322,8 +331,15 @@ class SegModel(object):
 
                 # update metrics logs
                 for metric_fn in self.metrics:
-                    metric_value = metric_fn(y_pred, y).cpu().detach().numpy()
-                    metrics_meters[metric_fn.__name__].add(metric_value)
+                    # metric_value = metric_fn(y_pred, y_gts).cpu().detach().numpy()
+                    # metrics_meters[metric_fn.__name__].add(metric_value)
+
+                    for cls in range(0, max(2, self.cfg.MODEL.NUM_CLASSES)):
+                        # metric_value = metric_fn(y_pred[:,cls,...], y[:,cls,...]).cpu().detach().numpy()
+                        cls_pred = (y_pred==cls).type(torch.FloatTensor)
+                        cls_gts = (y_gts==cls).type(torch.FloatTensor)
+                        metric_value = metric_fn(cls_pred, cls_gts).cpu().detach().numpy()
+                        metrics_meters[f"{metric_fn.__name__}_class{cls}"].add(metric_value)
 
                 metrics_logs = {k: v.mean for k, v in metrics_meters.items()}
                 logs.update(metrics_logs)
@@ -372,11 +388,10 @@ def run_app(cfg : DictConfig) -> None:
     from prettyprinter import pprint
     
     cfg_dict = OmegaConf.to_container(cfg, resolve=True)
-    cfg_flat = pd.json_normalize(cfg_dict, sep='.').to_dict(orient='records')[0]
+    cfg_flat = pd.json_normalize(cfg_dict, sep='_').to_dict(orient='records')[0]
 
-    # cfg.MODEL.DEBUG = False
-    # if not cfg.MODEL.DEBUG:
-    wandb.init(config=cfg_flat, project=cfg.PROJECT.NAME, entity=cfg.PROJECT.ENTITY, name=cfg.EXP.NAME)
+    wandb.init(config=cfg_flat, project="wildfire-s1s2alos-canada-rse", entity=cfg.PROJECT.ENTITY, name=cfg.EXP.NAME)
+    # wandb.init(config=cfg_flat, project=cfg.PROJECT.NAME, entity=cfg.PROJECT.ENTITY, name=cfg.EXP.NAME)
     pprint(cfg_flat)
 
     ''' train '''
diff --git a/models/model_selection.py b/models/model_selection.py
index 9a65643..6a5ea01 100644
--- a/models/model_selection.py
+++ b/models/model_selection.py
@@ -1,14 +1,23 @@
 
 from logging import error
 import smp
-from models.unet import UNet
-from models.siam_unet import SiamUnet_conc, SiamUnet_diff
+from models.unet import UNet, UNet_dualHeads
+from models.attention_unet import AttentionUNet
+
+from models.siam_unet import SiamUnet_conc, SiamUnet_diff, DualUnet_LF
 from models.unet_cdc import UNet as cdc_unet
 from models.siam_unet_resnet import SiamResUnet
 
 from models.unet_distill import UNet as distill_unet
 from models.segformer import segformer_models
 
+
+model_zoo = {
+    'UNet': UNet,
+    'att_UNet': AttentionUNet,
+    'UNet_dualHeads': UNet_dualHeads,
+}
+
 def get_model(cfg):
 
     ########################### COMPUTE INPUT & OUTPUT CHANNELS ############################
@@ -25,25 +34,34 @@ def get_model(cfg):
         INPUT_CHANNELS_LIST.append(INPUT_CHANNELS_DICT[sat])
     
     ########################### MODEL SELECTION ############################
-    if cfg.MODEL.ARCH == "UNet":
+    if cfg.MODEL.ARCH in model_zoo.keys():
         INPUT_CHANNELS = sum(INPUT_CHANNELS_LIST)
-        model = UNet(INPUT_CHANNELS, 
-                        num_classes=cfg.MODEL.NUM_CLASSES, 
-                        topo=cfg.MODEL.TOPO,
-                        use_deconv=cfg.MODEL.USE_DECONV) #'FC-EF'
+        MODEL = model_zoo[cfg.MODEL.ARCH]
+        return MODEL(INPUT_CHANNELS, 
+                    num_classes=cfg.MODEL.NUM_CLASSES, 
+                    topo=cfg.MODEL.TOPO,
+                    use_deconv=cfg.MODEL.USE_DECONV) #'FC-EF'
+
+    # if cfg.MODEL.ARCH == "UNet":
+    #     INPUT_CHANNELS = sum(INPUT_CHANNELS_LIST)
+    #     model = UNet(INPUT_CHANNELS, 
+    #                     num_classes=cfg.MODEL.NUM_CLASSES, 
+    #                     topo=cfg.MODEL.TOPO,
+    #                     use_deconv=cfg.MODEL.USE_DECONV) #'FC-EF'
+
 
     if cfg.MODEL.ARCH == 'distill_unet':
         INPUT_CHANNELS = INPUT_CHANNELS_LIST[0] # defined by the first sensor
-        model = UNet(INPUT_CHANNELS, 
+        return UNet(INPUT_CHANNELS, 
                         num_classes=cfg.MODEL.NUM_CLASSES, 
                         topo=cfg.MODEL.TOPO, 
                     ) #'FC-Siam-diff'
 
     if cfg.MODEL.ARCH in segformer_models.keys():
         INPUT_CHANNELS = sum(INPUT_CHANNELS_LIST)
-        model = segformer_models[cfg.MODEL.ARCH](in_channels=INPUT_CHANNELS, num_classes=cfg.MODEL.NUM_CLASSES)
+        return segformer_models[cfg.MODEL.ARCH](in_channels=INPUT_CHANNELS, num_classes=cfg.MODEL.NUM_CLASSES)
     
-    if "SiamUnet" in cfg.MODEL.ARCH:
+    if cfg.MODEL.ARCH in ['SiamUnet_conc', 'SiamUnet_diff', 'DualUnet_LF']:
         if len(INPUT_CHANNELS_LIST) == 1: # single sensor
             INPUT_CHANNELS = INPUT_CHANNELS_LIST[0]
         elif len(INPUT_CHANNELS_LIST) == 2: # two sensors
@@ -54,14 +72,21 @@ def get_model(cfg):
                 print("INPUT_CHANNELS is a list, pleae fix it!")
 
         if cfg.MODEL.ARCH == "SiamUnet_conc":
-            model = SiamUnet_conc(INPUT_CHANNELS, cfg.MODEL.NUM_CLASSES, \
+            return SiamUnet_conc(INPUT_CHANNELS, cfg.MODEL.NUM_CLASSES, \
                                 topo=cfg.MODEL.TOPO, 
                                 share_encoder=cfg.MODEL.SHARE_ENCODER,
                                 use_deconv=cfg.MODEL.USE_DECONV
                             ) #'FC-Siam-conc'
 
         if cfg.MODEL.ARCH == "SiamUnet_diff":
-            model = SiamUnet_diff(INPUT_CHANNELS, cfg.MODEL.NUM_CLASSES, 
+            return SiamUnet_diff(INPUT_CHANNELS, cfg.MODEL.NUM_CLASSES, 
+                                topo=cfg.MODEL.TOPO, 
+                                share_encoder=cfg.MODEL.SHARE_ENCODER,
+                                use_deconv=cfg.MODEL.USE_DECONV
+                            ) #'FC-Siam-diff'
+
+        if cfg.MODEL.ARCH == "DualUnet_LF":
+            return DualUnet_LF(INPUT_CHANNELS, cfg.MODEL.NUM_CLASSES, 
                                 topo=cfg.MODEL.TOPO, 
                                 share_encoder=cfg.MODEL.SHARE_ENCODER,
                                 use_deconv=cfg.MODEL.USE_DECONV
@@ -69,10 +94,10 @@ def get_model(cfg):
 
     
     if cfg.MODEL.ARCH == "SiamUnet_minDiff":
-        model = SiamUnet_diff(INPUT_CHANNELS, cfg.MODEL.NUM_CLASSES, topo=cfg.MODEL.TOPO) #'FC-Siam-diff'
+        return SiamUnet_diff(INPUT_CHANNELS, cfg.MODEL.NUM_CLASSES, topo=cfg.MODEL.TOPO) #'FC-Siam-diff'
 
     if cfg.MODEL.ARCH == "cdc_unet":
-        model = cdc_unet(INPUT_CHANNELS, cfg.MODEL.NUM_CLASSES) #'FC-EF'
+        return cdc_unet(INPUT_CHANNELS, cfg.MODEL.NUM_CLASSES) #'FC-EF'
 
     ########################### Residual UNet ############################
     if cfg.MODEL.ARCH == f'UNet_{cfg.MODEL.ENCODER}':
@@ -80,7 +105,7 @@ def get_model(cfg):
         print(f"===> Network Architecture: {cfg.MODEL.ARCH}")
         # create segmentation model with pretrained encoder
 
-        model = smp.Unet(
+        return smp.Unet(
             encoder_name = cfg.MODEL.ENCODER, 
             encoder_weights = cfg.MODEL.ENCODER_WEIGHTS, 
             encoder_depth=cfg.MODEL.ENCODER_DEPTH,
@@ -115,7 +140,7 @@ def get_model(cfg):
             input_channels.append(tmp)
 
         from models.siam_unet_resnet import SiamResUnet
-        model = SiamResUnet(
+        return SiamResUnet(
             encoder_name = cfg.MODEL.ENCODER, 
             encoder_weights = cfg.MODEL.ENCODER_WEIGHTS, 
             in_channels = input_channels,
@@ -126,10 +151,10 @@ def get_model(cfg):
     # print("==================================")
     # print(model)
     # print("==================================")
-    print("INPUT_CHANNELS: ", INPUT_CHANNELS)
-    print()
+    # print("INPUT_CHANNELS: ", INPUT_CHANNELS)
+    # print()
 
-    return model
+    # return model
 
 
 
diff --git a/models/segformer.py b/models/segformer.py
index ae238e5..4217493 100644
--- a/models/segformer.py
+++ b/models/segformer.py
@@ -128,7 +128,7 @@ class SegFormer(nn.Module):
             mode='bilinear',
             align_corners=self.align_corners)
         c1_ = self.linear_c1(c1).permute([0, 2, 1])
-        _c1 = c1_.reshape(*c2_.shape[:2], c1_shape[2], c1_shape[3])
+        _c1 = c1_.reshape(*c1_.shape[:2], c1_shape[2], c1_shape[3])
 
         _c = self.linear_fuse(torch.cat([_c4, _c3, _c2, _c1], axis=1))
 
diff --git a/models/siam_unet.py b/models/siam_unet.py
index d6d8ac1..1f5ad7b 100644
--- a/models/siam_unet.py
+++ b/models/siam_unet.py
@@ -110,6 +110,81 @@ class SiamUnet_conc(nn.Module):
         # logit_list.append(logit)
         return logit_list
 
+
+class DualUnet_LF(nn.Module):
+    """
+    The Dual UNet with late fusion (LF).
+    Args:
+        num_classes (int): The unique number of target classes.
+        align_corners (bool): An argument of F.interpolate. It should be set to False when the output size of feature
+            is even, e.g. 1024x512, otherwise it is True, e.g. 769x769.  Default: False.
+        use_deconv (bool, optional): A bool value indicates whether using deconvolution in upsampling.
+            If False, use resize_bilinear. Default: False.
+        pretrained (str, optional): The path or url of pretrained model for fine tuning. Default: None.
+    """
+
+    def __init__(self,
+                 input_channels=6,
+                 num_classes=1,
+                #  topo=[64, 128, 256, 512],
+                #  topo=[32, 64, 128, 256],
+                 topo=[16, 32, 64, 128],
+                 align_corners=False,
+                 use_deconv=False,
+                 pretrained=None,
+                 share_encoder=True):
+        super().__init__()
+
+        self.share_encoder = share_encoder
+        self.encode1 = Encoder(input_channels, topo=topo)
+        if not self.share_encoder:
+            self.encode2 = Encoder(input_channels, topo=topo)
+        else:
+            self.encode2 = self.encode1
+
+        decoder_topo = topo[::-1]
+        # decoder_topo = [3*de_topo for de_topo in decoder_topo]
+
+        self.decode1 = Decoder(align_corners, use_deconv=use_deconv, topo=decoder_topo, multiplyer=2)
+        if not self.share_encoder:
+            self.decode2 = Decoder(align_corners, use_deconv=use_deconv, topo=decoder_topo, multiplyer=2)
+        else:
+            self.decode2 = self.decode1
+
+        self.cls = self.conv = nn.Conv2d(
+            in_channels=topo[0] * 2, # *3 only for SiamUnet_conc
+            out_channels=num_classes,
+            kernel_size=3,
+            stride=1,
+            padding=1)
+
+        # self.pretrained = pretrained
+        # self.init_weight()
+
+        print(f"Encoder TOPO: ", topo)
+        # print(f"Decoder TOPO: ", decoder_topo)
+
+    def forward(self, x):
+        ''' x1, x2 should come from different sensor, or different time '''
+        x1, x2 = x
+
+        logit_list = []
+
+        xc1, short_cuts1 = self.encode1(x1)
+        x1 = self.decode1(xc1, short_cuts1)
+
+        xc2, short_cuts2 = self.encode2(x2)
+        x2 = self.decode2(xc2, short_cuts2)
+
+        x = torch.cat([x1, x2], dim=1)
+        x = self.cls(x) # output
+        logit_list.append(x)
+
+        # logit = nn.LogSoftmax(dim=1)(x)
+        # logit_list.append(logit)
+        return logit_list
+
+
 class SiamUnet_diff(nn.Module):
     """
     The UNet implementation based on PaddlePaddle.
@@ -176,7 +251,7 @@ class SiamUnet_diff(nn.Module):
         for cut1, cut2 in zip(short_cuts1, short_cuts2):
             # stacked_feat = torch.cat((cut1, cut2), dim=1)
             diff_feat = torch.subtract(cut1, cut2)
-            # diff_feat = torch.abs(diff_feat)
+            diff_feat = torch.abs(diff_feat)
             short_cut.append(diff_feat)
 
         # print("--------------------")
@@ -334,8 +409,8 @@ if __name__ == "__main__":
     x1 = torch.from_numpy(x1).type(torch.FloatTensor)#.cuda().type(torch.cuda.FloatTensor)
     x2 = torch.from_numpy(x2).type(torch.FloatTensor)#.cuda().type(torch.cuda.FloatTensor)
 
-    myunet = SiamUnet_conc(input_channels=6, share_encoder=True)
-    myunet1 = SiamUnet_diff(input_channels=6, share_encoder=True)
+    myunet = DualUnet_LF(input_channels=6, share_encoder=True)
+    # myunet1 = DualUnet_LF(input_channels=6, share_encoder=True)
     # myunet.cuda()
 
     # print(myunet)
diff --git a/models/unet.py b/models/unet.py
index 03d11c4..cd6aecf 100644
--- a/models/unet.py
+++ b/models/unet.py
@@ -85,6 +85,80 @@ class UNet(nn.Module):
         #     print(shortcut.shape)
 
         x = self.decode(xc, short_cuts)
+
+        x = self.cls(x) # output
+        logit_list.append(x)
+
+        return logit_list
+
+
+class UNet_dualHeads(nn.Module):
+    """
+    The UNet implementation based on PaddlePaddle.
+
+    The original article refers to
+    Olaf Ronneberger, et, al. "U-Net: Convolutional Networks for Biomedical Image Segmentation"
+    (https://arxiv.org/abs/1505.04597).
+
+    Args:
+        num_classes (int): The unique number of target classes.
+        align_corners (bool): An argument of F.interpolate. It should be set to False when the output size of feature
+            is even, e.g. 1024x512, otherwise it is True, e.g. 769x769.  Default: False.
+        use_deconv (bool, optional): A bool value indicates whether using deconvolution in upsampling.
+            If False, use resize_bilinear. Default: False.
+        pretrained (str, optional): The path or url of pretrained model for fine tuning. Default: None.
+    """
+
+    def __init__(self,
+            input_channels=6,
+            num_classes=2,
+            # topo=[64, 128, 256, 512],
+            topo=[16, 32, 64, 128],
+            # topo=[16, 32, 64],
+            align_corners=False,
+            use_deconv=False, # False
+            pretrained=None):
+        super().__init__()
+
+        self.encode = Encoder(input_channels, topo=topo)
+        decoder_topo = topo[::-1]
+        self.decode = Decoder(align_corners, use_deconv=use_deconv, topo=decoder_topo)
+        
+        self.cls = nn.Conv2d(
+            in_channels=topo[0],
+            out_channels=2, # burned areas
+            kernel_size=3,
+            stride=1,
+            padding=1)
+
+        self.reg_head = nn.Conv2d(
+            in_channels=topo[0],
+            out_channels=1,
+            kernel_size=3,
+            stride=1,
+            padding=1)
+
+        # self.sigmoid = nn.Sigmoid()
+        # self.softmax = nn.Softmax(dim=1)
+
+        # self.pretrained = pretrained
+        # self.init_weight()
+
+    def forward(self, x):
+        ''' x should be a list or tuple '''
+        x = torch.cat(x, dim=1) # concat all input tensors
+
+        logit_list = []
+        xc, short_cuts = self.encode(x)
+        # logit_list.append(xc) # most center features
+
+        # for shortcut in short_cuts:
+        #     print(shortcut.shape)
+
+        x = self.decode(xc, short_cuts)
+        reg_out = self.reg_head(x)
+        logit_list.append(reg_out)
+        
         x = self.cls(x) # output
         logit_list.append(x)
 
@@ -240,14 +314,14 @@ if __name__ == "__main__":
 
     torch.use_deterministic_algorithms(True)
 
-    x1 = np.random.rand(10,12,256,256)
+    x1 = np.random.rand(10,3,256,256)
     # x2 = np.random.rand(10,3,256,256)
-    x1 = torch.from_numpy(x1).type(torch.FloatTensor).cuda().type(torch.cuda.FloatTensor)
+    x1 = torch.from_numpy(x1).type(torch.FloatTensor)#.cuda().type(torch.cuda.FloatTensor)
     # x2 = torch.from_numpy(x2).type(torch.FloatTensor)#.cuda().type(torch.cuda.FloatTensor)
 
     myunet = UNet(input_channels=x1.shape[1])
     # myunet.cuda()
 
     print(myunet)
-    # print(myunet.forward([x1])[-1].shape)
+    print(myunet.forward([x1])[-1].shape)
     # summary(myunet, (3,256,256))
\ No newline at end of file
diff --git a/note.md b/note.md
index f16914c..ce9e3aa 100644
--- a/note.md
+++ b/note.md
@@ -5,4 +5,5 @@ Dice loss only accept binarized input, fixed.
 
 # Torch or Paddle 
 ## paddle models 
-## mmsegmentation (SegTransformer)
\ No newline at end of file
+## mmsegmentation (SegTransformer)
+
diff --git a/run_on_geoinfo/run_eval.sh b/run_on_geoinfo/run_eval.sh
index 1a7d086..17ab3fc 100644
--- a/run_on_geoinfo/run_eval.sh
+++ b/run_on_geoinfo/run_eval.sh
@@ -44,14 +44,11 @@ PYTHONUNBUFFERED=1;
 #     experiment.note=eval
 
 # sbatch run_on_geoinfo/run_eval.sh
-python3 s1s2_evaluator.py \
-            --config-name=unet.yaml \
-            RAND.SEED=0 \
-            RAND.DETERMIN=True \
+python3 s1s2_evaluator_prg.py \
+            --config-name=s1s2_cfg_prg.yaml \
             DATA.SATELLITES=['S1'] \
             DATA.INPUT_BANDS.S2=['B4','B8','B12'] \
-            MODEL.DEBUG=False \
-            EXP.NOTE=prepost-wd-0.001-eval
+
 
 #rm -rf $SLURM_SUBMIT_DIR/*.log
 # rm -rf $SLURM_SUBMIT_DIR/*.out
diff --git a/run_on_geoinfo/run_siamunet.sh b/run_on_geoinfo/run_siamunet.sh
index 099e5b2..c8cd291 100644
--- a/run_on_geoinfo/run_siamunet.sh
+++ b/run_on_geoinfo/run_siamunet.sh
@@ -4,7 +4,7 @@
 #SBATCH --mem 36GB
 #SBATCH --cpus-per-task 8
 #SBATCH -t 7-00:00:00
-#SBATCH --job-name siam-unet
+#SBATCH --job-name dual-unet
 #SBATCH --output /home/p/u/puzhao/run_logs/%x-%A_%a.out
 
 echo "start"
@@ -23,39 +23,39 @@ nvidia-smi
 # CFG=${DIRS[$SLURM_ARRAY_TASK_ID]}
 # echo "Running simulation $CFG"
 
-# # Choose different sensors
-SAT=('SiamUnet_conc' 'SiamUnet_diff')
-CFG=${SAT[$SLURM_ARRAY_TASK_ID]}
-echo "Running simulation $CFG"
-# echo "python3 main_s1s2_unet.py model.batch_size=32"
-echo "---------------------------------------------------------------------------------------------------------------"
+# # # Choose different sensors
+# SAT=('DualUnet_LF' 'SiamUnet_conc' 'SiamUnet_diff')
+# CFG=${SAT[$SLURM_ARRAY_TASK_ID]}
+# echo "Running simulation $CFG"
+# # echo "python3 main_s1s2_unet.py model.batch_size=32"
+# echo "---------------------------------------------------------------------------------------------------------------"
 
 # singularity exec --nv /cephyr/users/puzhao/Alvis/PyTorch_v1.7.0-py3.sif python main_s1s2_unet.py s1s2_unet=$CFG
 conda activate pytorch
 PYTHONUNBUFFERED=1; 
 
-# sbatch --array=0-1 run_on_geoinfo/run_siamunet.sh
+##########################################################
+## ---- Same Siam-UNet for Single-Sensor Data ----
+##########################################################
+# sbatch --array=0-2 run_on_geoinfo/run_siamunet.sh
 
-# # SiamUnet-S2
-# python3 main_s1s2_siamunet_bitemporal.py \
-#             data.satellites=['S2'] \
-#             model.ARCH=$CFG \
-#             model.SHARE_ENCODER=True \
-#             model.batch_size=16 \
-#             model.max_epoch=100 \
-#             experiment.note=allBands
+# # Choose different sensors
+SAT=('S1' 'S2' 'ALOS')
+CFG=${SAT[$SLURM_ARRAY_TASK_ID]}
+echo "Running simulation $CFG"
+# echo "python3 main_s1s2_unet.py model.batch_size=32"
+echo "---------------------------------------------------------------------------------------------------------------"
 
-# # SiamUnet-S1
-# sbatch --array=0-1 run_on_geoinfo/run_siamunet.sh
 python3 main_s1s2_unet.py \
             --config-name=siam_unet.yaml \
             RAND.SEED=0 \
             RAND.DETERMIN=False \
-            DATA.SATELLITES=['S1'] \
+            DATA.TRAIN_MASK=poly \
+            DATA.SATELLITES=[$CFG] \
             DATA.STACKING=False \
             DATA.INPUT_BANDS.S1=['ND','VH','VV'] \
             DATA.INPUT_BANDS.S2=['B4','B8','B12'] \
-            MODEL.ARCH=$CFG \
+            MODEL.ARCH='DualUnet_LF' \
             MODEL.SHARE_ENCODER=True \
             MODEL.ENCODER=resnet18 \
             MODEL.ENCODER_WEIGHTS=imagenet \
@@ -67,7 +67,43 @@ python3 main_s1s2_unet.py \
             MODEL.ACTIVATION=sigmoid \
             MODEL.BATCH_SIZE=16 \
             MODEL.MAX_EPOCH=100 \
-            EXP.NOTE=abs
+            EXP.NOTE=LF
+
+##########################################################
+## ---- Different Architecture for Multi-Sensor Data ----
+##########################################################
+# sbatch --array=0-1 run_on_geoinfo/run_siamunet.sh
+
+# # Choose different sensors
+# SAT=('DualUnet_LF' 'SiamUnet_conc' 'SiamUnet_diff')
+# CFG=${SAT[$SLURM_ARRAY_TASK_ID]}
+# echo "Running simulation $CFG"
+# # echo "python3 main_s1s2_unet.py model.batch_size=32"
+# echo "---------------------------------------------------------------------------------------------------------------"
+
+# python3 main_s1s2_unet.py \
+#             --config-name=siam_unet.yaml \
+#             RAND.SEED=0 \
+#             RAND.DETERMIN=False \
+#             DATA.TRAIN_MASK=poly \
+#             DATA.SATELLITES=['S1','S2'] \
+#             DATA.STACKING=True \
+#             DATA.INPUT_BANDS.S1=['ND','VH','VV'] \
+#             DATA.INPUT_BANDS.S2=['B4','B8','B12'] \
+#             MODEL.ARCH=$CFG \
+#             MODEL.SHARE_ENCODER=True \
+#             MODEL.ENCODER=resnet18 \
+#             MODEL.ENCODER_WEIGHTS=imagenet \
+#             MODEL.USE_DECONV=False \
+#             MODEL.WEIGHT_DECAY=0.01 \
+#             MODEL.NUM_CLASSES=1 \
+#             MODEL.LOSS_TYPE=DiceLoss \
+#             MODEL.LR_SCHEDULER=cosine \
+#             MODEL.ACTIVATION=sigmoid \
+#             MODEL.BATCH_SIZE=16 \
+#             MODEL.MAX_EPOCH=100 \
+#             EXP.NOTE=Feb26
+
 
 # python3 main_s1s2_unet.py \
 #             --config-name=siam_unet.yaml \
@@ -92,14 +128,6 @@ python3 main_s1s2_unet.py \
 #             EXP.NOTE=Jan15
 
 
-# # SiamUnet-S1S2
-# python3 main_s1s2_siamunet_multisensor.py \
-#             data.satellites=['S1','S2'] \
-#             data.stacking=True \
-#             model.ARCH=$CFG \
-#             model.batch_size=16 \
-#             model.max_epoch=5 \
-#             experiment.note=test
 
 #rm -rf $SLURM_SUBMIT_DIR/*.log
 # rm -rf $SLURM_SUBMIT_DIR/*.out
diff --git a/run_on_geoinfo/run_unet.sh b/run_on_geoinfo/run_unet.sh
index 6cf8a4e..a380f5f 100644
--- a/run_on_geoinfo/run_unet.sh
+++ b/run_on_geoinfo/run_unet.sh
@@ -2,9 +2,9 @@
 #SBATCH -N 1
 #SBATCH --gres=gpu:1
 #SBATCH --mem 36GB
-#SBATCH --cpus-per-task 8
+#SBATCH --cpus-per-task 1
 #SBATCH -t 7-00:00:00
-#SBATCH --job-name sar-unet
+#SBATCH --job-name train
 #SBATCH --output /home/p/u/puzhao/run_logs/%x-%A_%a.out
 
 echo "start"
@@ -13,6 +13,9 @@ echo
 nvidia-smi
 . /geoinfo_vol1/puzhao/miniforge3/etc/profile.d/conda.sh
 
+conda activate pytorch
+PYTHONUNBUFFERED=1; 
+
 # module --ignore-cache load "intel"
 # PROJECT_DIR=/cephyr/NOBACKUP/groups/snic2021-7-104/puzhao-snic-500G/smp-seg-pytorch
 
@@ -23,70 +26,177 @@ nvidia-smi
 # CFG=${DIRS[$SLURM_ARRAY_TASK_ID]}
 # echo "Running simulation $CFG"
 
-# # Choose different sensors
-# echo "python3 main_s1s2_unet.py model.batch_size=32"
 
-# singularity exec --nv /cephyr/users/puzhao/Alvis/PyTorch_v1.7.0-py3.sif python main_s1s2_unet.py s1s2_unet=$CFG
-conda activate pytorch
-PYTHONUNBUFFERED=1; 
-
-# python3 main_s1s2_unet.py \
-#             data.satellites=['S2'] \
-#             data.INPUT_BANDS.S2=['B4','B8','B12']\
-#             model.ARCH=UNet \
-#             model.batch_size=16 \
-#             model.max_epoch=100 \
-#             experiment.note=B4812
+## sbatch --array=0-2 run_on_geoinfo/run_unet.sh
+# SAT=('S1' 'S2', 'ALOS')
+# CFG=${SAT[$SLURM_ARRAY_TASK_ID]}
+# echo "Running simulation $CFG"
+# echo "---------------------------------------------------------------------------------------------------------------"
 
-# sbatch run_on_geoinfo/run_unet.sh
-# python3 main_s1s2_unet.py \
-#             --config-name=unet \
-#             data.satellites=['S1'] \
-#             model.ARCH=UNet \
-#             model.batch_size=16 \
-#             model.max_epoch=5 \
-#             experiment.note=test
+# python3 test.py
 
 # python3 main_s1s2_unet.py \
-#             --config-name=unet \
-#             data.satellites=['S1','S2'] \
-#             data.INPUT_BANDS.S2=['B4','B8','B12'] \
-#             model.ARCH=UNet \
-#             model.batch_size=16 \
-#             model.max_epoch=100 \
-#             experiment.note=EF-new
+#             --config-name=unet.yaml \
+#             RAND.SEED=0 \
+#             RAND.DETERMIN=False \
+#             DATA.TRAIN_MASK=poly \
+#             DATA.SATELLITES=[$CFG] \
+#             DATA.PREPOST=['pre','post'] \
+#             DATA.STACKING=True \
+#             DATA.INPUT_BANDS.S2=['B4','B8','B12'] \
+#             MODEL.ARCH=UNet \
+#             MODEL.USE_DECONV=False \
+#             MODEL.WEIGHT_DECAY=0.01 \
+#             MODEL.NUM_CLASSES=1 \
+#             MODEL.LOSS_TYPE=DiceLoss \
+#             MODEL.LR_SCHEDULER=cosine \
+#             MODEL.ACTIVATION=sigmoid \
+#             MODEL.BATCH_SIZE=16 \
+#             MODEL.MAX_EPOCH=100 \
+#             EXP.NOTE=EF-no-deconv
 
 
 
-# python3 main_s1s2_unet.py \
-#             data.satellites=['S1','S2'] \
-#             data.INPUT_BANDS.S2=['B4','B8','B12'] \
-#             model.ARCH=distill_unet \
-#             model.batch_size=16 \
-#             model.max_epoch=100 \
-#             experiment.note=S1_TEST
+##########################################################
+## ---- U-Net multiple runs with different seeds ----
+##########################################################
+## sbatch --array=0-5 run_on_geoinfo/run_unet.sh
+CFG=$SLURM_ARRAY_TASK_ID
+echo "Running simulation $CFG"
+echo "---------------------------------------------------------------------------------------------------------------"
 
-# sbatch run_on_geoinfo/run_unet.sh
 python3 main_s1s2_unet.py \
             --config-name=unet.yaml \
-            RAND.SEED=0 \
+            RAND.SEED=$CFG \
             RAND.DETERMIN=False \
+            DATA.TRAIN_MASK=poly \
             DATA.SATELLITES=['S1'] \
-            MODEL.DEBUG=False \
             MODEL.ARCH=UNet \
             MODEL.ENCODER=resnet18 \
             MODEL.ENCODER_WEIGHTS=imagenet \
-            MODEL.USE_DECONV=True \
+            MODEL.USE_DECONV=False \
             MODEL.WEIGHT_DECAY=0.01 \
-            MODEL.NUM_CLASSES=1 \
-            MODEL.LOSS_TYPE=DiceLoss \
+            MODEL.NUM_CLASSES=2 \
+            MODEL.LOSS_TYPE=CrossEntropyLoss \
             MODEL.LR_SCHEDULER=cosine \
-            MODEL.ACTIVATION=sigmoid \
+            MODEL.ACTIVATION=softmax \
             MODEL.BATCH_SIZE=16 \
-            MODEL.MAX_EPOCH=100 \
+            MODEL.MAX_EPOCH=5 \
+            EXP.FOLDER=Canada_RSE_2022 \
             EXP.NOTE=EF
 
-# sbatch --array=0-2 run_on_geoinfo/run_unet.sh
+
+##########################################################
+## ---- U-Net MTBS ----
+##########################################################
+# sbatch run_on_geoinfo/run_unet.sh
+# python3 main_s1s2_unet_mtbs.py \
+#             --config-name=mtbs.yaml \
+#             RAND.SEED=0 \
+#             RAND.DETERMIN=False \
+#             DATA.AUGMENT=True \
+#             DATA.TRAIN_MASK=mtbs \
+#             DATA.TEST_MASK=mtbs \
+#             DATA.SATELLITES=['S2'] \
+#             DATA.PREPOST=['pre','post'] \
+#             DATA.STACKING=True \
+#             DATA.INPUT_BANDS.S2=['B4','B8','B12'] \
+#             MODEL.ARCH=UNet_dualHeads \
+#             MODEL.CLASS_WEIGHTS=[0.1,0.2,0.3,0.4] \
+#             MODEL.USE_DECONV=False \
+#             MODEL.WEIGHT_DECAY=0.01 \
+#             MODEL.LR_SCHEDULER=cosine \
+#             MODEL.BATCH_SIZE=32 \
+#             MODEL.MAX_EPOCH=100 \
+#             MODEL.STEP_WISE_LOG=False \
+#             EXP.NOTE=mtbs-mse-x10
+
+##########################################################
+## ---- U-Net MTBS 2 Classes ----
+##########################################################
+# sbatch run_on_geoinfo/run_unet.sh
+# python3 main_s1s2_unet_mtbs.py \
+#             --config-name=mtbs.yaml \
+#             RAND.SEED=0 \
+#             RAND.DETERMIN=False \
+#             DATA.TRAIN_MASK=poly \
+#             DATA.TRAIN_MASK=poly \
+#             DATA.SATELLITES=['S2'] \
+#             DATA.PREPOST=['pre','post'] \
+#             DATA.STACKING=True \
+#             DATA.INPUT_BANDS.S2=['B4','B8','B12'] \
+#             MODEL.ARCH=UNet \
+#             MODEL.NUM_CLASSES=2 \
+#             MODEL.CLASS_NAMES=['unburn','low'] \
+#             MODEL.CLASS_WEIGHTS=[0.5,0.5] \
+#             MODEL.USE_DECONV=True \
+#             MODEL.WEIGHT_DECAY=0.01 \
+#             MODEL.LR_SCHEDULER=cosine \
+#             MODEL.BATCH_SIZE=16 \
+#             MODEL.MAX_EPOCH=100 \
+#             EXP.NOTE=poly-ep100
+            
+
+
+
+
+##########################################################
+## ---- U-Net with Data Augmentation ----
+##########################################################
+# sbatch run_on_geoinfo/run_unet.sh
+# python3 main_s1s2_unet_aug.py \
+#             --config-name=unet.yaml \
+#             RAND.SEED=0 \
+#             RAND.DETERMIN=False \
+#             DATA.SATELLITES=['ALOS'] \
+#             DATA.TRAIN_MASK=poly \
+#             DATA.AUGMENT=False \
+#             MODEL.ARCH=UNet \
+#             MODEL.ENCODER=resnet18 \
+#             MODEL.ENCODER_WEIGHTS=imagenet \
+#             MODEL.USE_DECONV=False \
+#             MODEL.LEARNING_RATE=0.0001 \
+#             MODEL.WEIGHT_DECAY=0.01 \
+#             MODEL.NUM_CLASSES=1 \
+#             MODEL.LOSS_TYPE=DiceLoss \
+#             MODEL.LR_SCHEDULER=cosine \
+#             MODEL.ACTIVATION=sigmoid \
+#             MODEL.BATCH_SIZE=16 \
+#             MODEL.MAX_EPOCH=100 \
+#             EXP.NOTE=EF-aug
+
+
+##########################################################
+## ---- Weakly Supervised Learning ----
+##########################################################
+# sbatch run_on_geoinfo/run_unet.sh
+# python3 main_s1s2_unet_wsl.py \
+#             --config-name=unet.yaml \
+#             RAND.SEED=0 \
+#             RAND.DETERMIN=False \
+#             DATA.SATELLITES=['ALOS'] \
+#             DATA.INPUT_BANDS.S2=['B8','B11','B12'] \
+#             DATA.TRAIN_MASK=modis \
+#             DATA.AUGMENT=True \
+#             MODEL.ARCH=UNet \
+#             MODEL.ENCODER=resnet18 \
+#             MODEL.ENCODER_WEIGHTS=imagenet \
+#             MODEL.USE_DECONV=False \
+#             MODEL.LEARNING_RATE=0.0001 \
+#             MODEL.WEIGHT_DECAY=0.01 \
+#             MODEL.NUM_CLASSES=1 \
+#             MODEL.LOSS_TYPE=DiceLoss \
+#             MODEL.LR_SCHEDULER=cosine \
+#             MODEL.ACTIVATION=sigmoid \
+#             MODEL.BATCH_SIZE=16 \
+#             MODEL.MAX_EPOCH=100 \
+#             EXP.NOTE=EF-aug
+
+
+##########################################################
+## ---- Early Fusion for Single Bands for S1 and ALOS ----
+##########################################################          
+# # sbatch --array=0-2 run_on_geoinfo/run_unet.sh
 # SAT=('ND' 'VH' 'VV')
 # CFG=${SAT[$SLURM_ARRAY_TASK_ID]}
 # echo "Running simulation $CFG"
@@ -96,21 +206,87 @@ python3 main_s1s2_unet.py \
 #             --config-name=unet.yaml \
 #             RAND.SEED=0 \
 #             RAND.DETERMIN=False \
-#             DATA.SATELLITES=['S1'] \
-#             DATA.INPUT_BANDS.S1=[$CFG] \
-#             MODEL.DEBUG=False \
+#             DATA.TRAIN_MASK=poly \
+#             DATA.SATELLITES=['ALOS'] \
+#             DATA.INPUT_BANDS.ALOS=[$CFG] \
+#             MODEL.ARCH=UNet \
+#             MODEL.ENCODER=resnet18 \
+#             MODEL.ENCODER_WEIGHTS=imagenet \
+#             MODEL.USE_DECONV=True \
+#             MODEL.WEIGHT_DECAY=0.01 \
+#             MODEL.NUM_CLASSES=1 \
+#             MODEL.LOSS_TYPE=DiceLoss \
+#             MODEL.LR_SCHEDULER=cosine \
+#             MODEL.ACTIVATION=sigmoid \
+#             MODEL.BATCH_SIZE=16 \
+#             MODEL.MAX_EPOCH=100 \
+#             EXP.NOTE=$CFG
+
+
+
+##########################################################
+## ---- Early Fusion of Different Sensors ----
+##########################################################
+## sbatch --array=0-2 run_on_geoinfo/run_unet.sh
+# SAT=('S1' 'S2')
+# CFG=${SAT[$SLURM_ARRAY_TASK_ID]}
+# echo "Running simulation $CFG"
+# echo "---------------------------------------------------------------------------------------------------------------"
+
+# python3 main_s1s2_unet.py \
+#             --config-name=unet.yaml \
+#             RAND.SEED=0 \
+#             RAND.DETERMIN=False \
+#             DATA.TRAIN_MASK=poly \
+#             DATA.SATELLITES=[$CFG,'ALOS'] \
+#             DATA.PREPOST=['pre','post'] \
+#             DATA.STACKING=True \
+#             DATA.INPUT_BANDS.S2=['B4','B8','B12'] \
+#             MODEL.ARCH=UNet \
+#             MODEL.ENCODER=resnet18 \
+#             MODEL.ENCODER_WEIGHTS=imagenet \
+#             MODEL.USE_DECONV=True \
+#             MODEL.WEIGHT_DECAY=0.01 \
+#             MODEL.NUM_CLASSES=1 \
+#             MODEL.LOSS_TYPE=DiceLoss \
+#             MODEL.LR_SCHEDULER=cosine \
+#             MODEL.ACTIVATION=sigmoid \
+#             MODEL.BATCH_SIZE=16 \
+#             MODEL.MAX_EPOCH=100 \
+#             EXP.NOTE=EF
+
+
+
+##########################################################
+## --- Use Post-Fire Data alone for single sensor ---
+##########################################################
+## sbatch --array=0-2 run_on_geoinfo/run_unet.sh
+# SAT=('S1' 'S2' 'ALOS')
+# CFG=${SAT[$SLURM_ARRAY_TASK_ID]}
+# echo "Running simulation $CFG"
+# echo "---------------------------------------------------------------------------------------------------------------"
+
+# python3 main_s1s2_unet.py \
+#             --config-name=unet.yaml \
+#             RAND.SEED=0 \
+#             RAND.DETERMIN=False \
+#             DATA.TRAIN_MASK=poly \
+#             DATA.SATELLITES=[$CFG] \
+#             DATA.PREPOST=['post'] \
+#             DATA.STACKING=False \
+#             DATA.INPUT_BANDS.S2=['B4','B8','B12'] \
 #             MODEL.ARCH=UNet \
-            # MODEL.ENCODER=resnet18 \
-            # MODEL.ENCODER_WEIGHTS=imagenet \
-            # MODEL.USE_DECONV=True \
-            # MODEL.WEIGHT_DECAY=0.01 \
-            # MODEL.NUM_CLASSES=1 \
-            # MODEL.LOSS_TYPE=DiceLoss \
-            # MODEL.LR_SCHEDULER=cosine \
-            # MODEL.ACTIVATION=sigmoid \
-            # MODEL.BATCH_SIZE=16 \
-            # MODEL.MAX_EPOCH=100 \
-            # EXP.NOTE=$CFG
+#             MODEL.ENCODER=resnet18 \
+#             MODEL.ENCODER_WEIGHTS=imagenet \
+#             MODEL.USE_DECONV=True \
+#             MODEL.WEIGHT_DECAY=0.01 \
+#             MODEL.NUM_CLASSES=1 \
+#             MODEL.LOSS_TYPE=DiceLoss \
+#             MODEL.LR_SCHEDULER=cosine \
+#             MODEL.ACTIVATION=sigmoid \
+#             MODEL.BATCH_SIZE=16 \
+#             MODEL.MAX_EPOCH=100 \
+#             EXP.NOTE=post
 
 #rm -rf $SLURM_SUBMIT_DIR/*.log
 # rm -rf $SLURM_SUBMIT_DIR/*.out
diff --git a/s1s2_evaluator.py b/s1s2_evaluator.py
index e2ce27d..54355ed 100644
--- a/s1s2_evaluator.py
+++ b/s1s2_evaluator.py
@@ -64,7 +64,7 @@ def inference(model, test_dir, test_id, cfg):
         model.to("cuda")
 
     ''' read input data '''
-    input_tensors = []
+    input_tensors = []  # [(S1_pre, S1_post), (S2_pre, S2_post), ...]
     for sat in cfg.DATA.SATELLITES:
         
         post_url = test_dir / sat / "post" / f"{test_id}.tif"
@@ -90,10 +90,10 @@ def inference(model, test_dir, test_id, cfg):
             input_tensors.append((pre_image_tensor, post_image_tensor))
 
         else:
-            input_tensors.append(post_image_tensor)
+            input_tensors.append((post_image_tensor, ))
 
     C, H, W = post_image.shape
-    _, _, Height, Width = input_tensors[0][0].shape
+    _, _, Height, Width = post_image_tensor.shape
     pred_mask_pad = np.zeros((Height, Width)) #HxW
     prob_mask_pad = np.zeros((Height, Width)) #HxW
 
@@ -107,7 +107,7 @@ def inference(model, test_dir, test_id, cfg):
             ''' ------------> tile input data <---------- '''
             input_patchs = []
             for sat_tensor in input_tensors:
-                post_patch = (sat_tensor[1][..., i:i+input_patchsize, j:j+input_patchsize]).type(torch.cuda.FloatTensor)
+                post_patch = (sat_tensor[-1][..., i:i+input_patchsize, j:j+input_patchsize]).type(torch.cuda.FloatTensor)
                 if 'pre' in cfg.DATA.PREPOST: 
                     pre_patch = (sat_tensor[0][..., i:i+input_patchsize, j:j+input_patchsize]).type(torch.cuda.FloatTensor)
                     
@@ -147,23 +147,20 @@ def inference(model, test_dir, test_id, cfg):
             ''' ------------------------------------------ '''
             activation = Activation(name=cfg.MODEL.ACTIVATION)
             predPatch = activation(out) #NCWH for sigmoid, NWH for argmax, N=1, C=1
-            predPatch = predPatch.squeeze() #1x1xWxH or 1xWxH -> WxH
-
-            predPatch = predPatch.cpu().detach().numpy()
             if 'sigmoid' == cfg.MODEL.ACTIVATION:
-                predLabel = np.round(predPatch) # binarized with 0.5
+                predLabel = np.round(predPatch.squeeze().cpu().detach().numpy()) # binarized with 0.5
             else: # 'argmax'
-                predLabel = predPatch
+                predLabel = torch.argmax(predPatch, dim=1)
+                predLabel = predLabel.squeeze().cpu().detach().numpy()
             
             ''' save predicted tile '''
-            prob_mask_pad[i+padSize:i+padSize+patchsize, j+padSize:j+padSize+patchsize] = predPatch[padSize:padSize+patchsize, padSize:padSize+patchsize]
             pred_mask_pad[i+padSize:i+padSize+patchsize, j+padSize:j+padSize+patchsize] = predLabel[padSize:padSize+patchsize, padSize:padSize+patchsize]
 
     ''' clip back into original shape '''        
     pred_mask = pred_mask_pad[padSize:padSize+H, padSize:padSize+W] # clip back to original shape
-    prod_mask = prob_mask_pad[padSize:padSize+H, padSize:padSize+W] # clip back to original shape
+    # prod_mask = prob_mask_pad[padSize:padSize+H, padSize:padSize+W] # clip back to original shape
 
-    return pred_mask, prod_mask
+    return pred_mask
 
 def gen_errMap(grouthTruth, preMap, save_url=False):
     errMap = np.zeros(preMap.shape)
@@ -201,8 +198,7 @@ def apply_model_on_event(model, test_id, output_dir, cfg):
 
     print(f"------------------> {test_id} <-------------------")
 
-    predMask, probMask = inference(model, data_dir, event, cfg)
-
+    predMask = inference(model, data_dir, event, cfg)
     print(f"predMask shape: {predMask.shape}, unique: {np.unique(predMask)}")
     # print(f"probMask: [{probMask.min()}, {probMask.max()}]")
 
@@ -210,19 +206,18 @@ def apply_model_on_event(model, test_id, output_dir, cfg):
     # # [0,100/255,0]
     # mtbs_palette = [[0,100/255,0], [127/255,1,212/255], [1,1,0], [1,0,0], [127/255,1,0], [1,1,1]]
 
-    plt.imsave(output_dir / f"{test_id}_pred.png", predMask, cmap='gray', vmin=0, vmax=1)
-    # plt.imsave(output_dir / f"{test_id}_probMap.png", predMask, cmap='gray', vmin=0, vmax=1)
-
-        # read and save true labels
-    if os.path.isfile(data_dir / "mask" / "poly" / f"{event}.tif"):
-        trueLabel = tiff.imread(data_dir / "mask" / "poly" / f"{event}.tif")
+    tiff.imsave(output_dir / f"{test_id}_pred.tif", predMask)
+    # imsave(output_dir / f"{test_id}_pred.png", predMask)
+    
+    # read and save true labels
+    if os.path.isfile(data_dir / "mask" / cfg.DATA.TEST_MASK / f"{event}.tif"):
+        trueLabel = tiff.imread(data_dir / "mask" / cfg.DATA.TEST_MASK / f"{event}.tif")
         # _, _, trueLabel = geotiff.read(data_dir / "mask" / "poly" / f"{event}.tif")
         # geotiff.save(output_dir / f"{test_id}_predLabel.tif", predMask[np.newaxis,]) 
 
         trueLabel = trueLabel.squeeze()
-        # print(trueLabel.shape, predMask.shape)
 
-        plt.imsave(output_dir / f"{test_id}_gts.png", trueLabel, cmap='gray', vmin=0, vmax=1)
+        # plt.imsave(output_dir / f"{test_id}_gts.png", trueLabel, cmap='gray', vmin=0, vmax=1)
         gen_errMap(trueLabel, predMask, save_url=output_dir / f"{test_id}.png")
 
 
@@ -308,7 +303,7 @@ def run_app(cfg : DictConfig) -> None:
     # for test_id in test_id_list:
     #     apply_model_on_event(model, test_id, output_dir, satellites=['S1', 'S2'])
 
-    run_dir = Path("/home/p/u/puzhao/smp-seg-pytorch/outputs/run_s1s2_UNet_resnet18_['S1']_prepost-wd-1e-3_20220113T202555")
+    run_dir = Path("/home/p/u/puzhao/smp-seg-pytorch/outputs/run_s1s2_UNet_['S2']_post_20220226T084623")
     model_url = run_dir / "model.pth"
     output_dir = run_dir / "errMap"
     evaluate_model(cfg, model_url, output_dir)
diff --git a/s1s2_evaluator_prg.py b/s1s2_evaluator_prg.py
index a49778c..bb9e9f5 100644
--- a/s1s2_evaluator_prg.py
+++ b/s1s2_evaluator_prg.py
@@ -10,6 +10,7 @@ from pathlib import Path
 import tifffile as tiff
 import smp
 from easydict import EasyDict as edict
+from smp.base.modules import Activation
 
 import matplotlib.pyplot as plt
 from matplotlib.colors import ListedColormap, LinearSegmentedColormap
@@ -35,8 +36,8 @@ def image_padding(img, patchsize):
     return img_pad
 
 def get_band_index_dict(cfg):
-    ALL_BANDS = cfg.data.ALL_BANDS
-    INPUT_BANDS = cfg.data.INPUT_BANDS
+    ALL_BANDS = cfg.DATA.ALL_BANDS
+    INPUT_BANDS = cfg.DATA.INPUT_BANDS
 
     def get_band_index(sat):
         all_bands = list(ALL_BANDS[sat])
@@ -55,16 +56,15 @@ def get_band_index_dict(cfg):
 
 def inference(model, test_dir, test_id, cfg):
 
-    patchsize = cfg.eval.patchsize
-    NUM_CLASS = len(list(cfg.data.CLASSES))
+    patchsize = cfg.EVAL.PATCHSIZE
+    NUM_CLASS = cfg.MODEL.NUM_CLASSES
     # model.cpu()
     model.to("cuda")
 
     input_tensors = []
-    for sat in cfg.data.satellites:
+    for sat in cfg.DATA.SATELLITES:
         
         post_url = test_dir / sat / "post" / f"{test_id}.tif"
-        orbKey = test_id.split("_")[-1]
 
         post_image = tiff.imread(post_url).transpose(2,0,1) # C*H*W
         post_image = np.nan_to_num(post_image, 0)
@@ -78,10 +78,11 @@ def inference(model, test_dir, test_id, cfg):
         # img_preprocessed = self.preprocessing_fn(img_pad)
         post_image_tensor = torch.from_numpy(post_image_pad).unsqueeze(0) # n * C * H * W
         
-        if 'pre' in cfg.data.prepost:
+        if 'pre' in cfg.DATA.PREPOST:
             pre_folder = test_dir / sat / "pre"
             # pre_url = pre_folder / os.listdir(pre_folder)[0]
-            pre_url = glob.glob(f"{str(pre_folder)}/*{orbKey}.tif")[0]
+            query = test_id.split("_")[-1]
+            pre_url = glob.glob(str(pre_folder / f"*_{query}.tif"))[0]
             print("pre_image: ", os.path.split(pre_url)[-1])
 
             pre_image = tiff.imread(pre_url).transpose(2,0,1)
@@ -101,7 +102,7 @@ def inference(model, test_dir, test_id, cfg):
     C, H, W = post_image.shape
     _, _, Height, Width = input_tensors[0][0].shape
     pred_mask_pad = np.zeros((Height, Width))
-    prob_mask_pad = np.zeros((NUM_CLASS, Height, Width))
+    # prob_mask_pad = np.zeros((NUM_CLASS, Height, Width))
 
     input_patchsize = 2 * patchsize
     padSize = int(patchsize/2) 
@@ -113,10 +114,10 @@ def inference(model, test_dir, test_id, cfg):
             input_patchs = []
             for sat_tensor in input_tensors:
                 post_patch = (sat_tensor[1][..., i:i+input_patchsize, j:j+input_patchsize]).type(torch.cuda.FloatTensor)
-                if 'pre' in cfg.data.prepost: 
+                if 'pre' in cfg.DATA.PREPOST: 
                     pre_patch = (sat_tensor[0][..., i:i+input_patchsize, j:j+input_patchsize]).type(torch.cuda.FloatTensor)
                     
-                    if cfg.data.stacking: 
+                    if cfg.DATA.STACKING: 
                         inputPatch = torch.cat([pre_patch, post_patch], dim=1) # stacked inputs
                         input_patchs.append(inputPatch)
                     else:
@@ -124,23 +125,45 @@ def inference(model, test_dir, test_id, cfg):
                 else:
                     input_patchs.append(post_patch)
 
-            ''' ------------> apply model <--------------- '''
-            if 'FuseUNet' in cfg.model.ARCH:
-                predPatch, _ = model.forward(input_patchs)
-            else:
-                predPatch = model.forward(inputPatch)
-            ''' ------------------------------------------ '''
+            if 'distill_unet' == cfg.MODEL.ARCH:
+                if cfg.MODEL.DISTILL:
+                    out = model.forward(input_patchs[:1])[-1] # ONLY USE S1 sensor in distill mode.
+                else:
+                    out = model.forward(input_patchs)[-1] # USE all data in pretrain mode.
+
+            elif 'UNet_resnet' in cfg.MODEL.ARCH:
+                out = model.forward(torch.cat(input_patchs, dim=1))
 
-            predPatch = predPatch.squeeze().cpu().detach().numpy()#.round()
-            predLabel = np.argmax(predPatch, axis=0).squeeze()
+            # elif 'SiamResUNet' in cfg.MODEL.ARCH:
+            #     out, decoder_out = model.forward(input_patchs, False)
 
-            pred_mask_pad[i+padSize:i+padSize+patchsize, j+padSize:j+padSize+patchsize] = predLabel[padSize:padSize+patchsize, padSize:padSize+patchsize]  # need to modify
-            prob_mask_pad[:, i+padSize:i+padSize+patchsize, j+padSize:j+padSize+patchsize] = predPatch[:, padSize:padSize+patchsize, padSize:padSize+patchsize]  # need to modify
+            # elif 'cdc_unet' in cfg.MODEL.ARCH:
+            #     out, decoder_out = model.forward(input_patchs, False)
+            
+            else: # UNet, SiamUnet
+                # NEW: input_patchs should be a list or tuple, the last one is the wanted output.
+                out = model.forward(input_patchs)[-1] 
 
+            ''' ------------------------------------------ '''
+            activation = Activation(name=cfg.MODEL.ACTIVATION)
+            predPatch = activation(out) #NCWH for sigmoid, NWH for argmax, N=1, C=1
+            predPatch = predPatch.squeeze() #1x1xWxH or 1xWxH -> WxH
+
+            predPatch = predPatch.cpu().detach().numpy()
+            if 'sigmoid' == cfg.MODEL.ACTIVATION:
+                predLabel = np.round(predPatch) # binarized with 0.5
+            else: # 'argmax'
+                predLabel = predPatch
+            
+            ''' save predicted tile '''
+            # prob_mask_pad[i+padSize:i+padSize+patchsize, j+padSize:j+padSize+patchsize] = predPatch[padSize:padSize+patchsize, padSize:padSize+patchsize]
+            pred_mask_pad[i+padSize:i+padSize+patchsize, j+padSize:j+padSize+patchsize] = predLabel[padSize:padSize+patchsize, padSize:padSize+patchsize]
+
+    ''' clip back into original shape '''    
+    # prob_mask = prob_mask_pad[padSize:padSize+H, padSize:padSize+W] # clip back to original shape    
     pred_mask = pred_mask_pad[padSize:padSize+H, padSize:padSize+W] # clip back to original shape
-    prod_mask = prob_mask_pad[:, padSize:padSize+H, padSize:padSize+W] # clip back to original shape
 
-    return pred_mask, prod_mask
+    return pred_mask
 
 def gen_errMap(grouthTruth, preMap, save_url=False):
     errMap = np.zeros(preMap.shape)
@@ -169,7 +192,7 @@ def gen_errMap(grouthTruth, preMap, save_url=False):
 def apply_model_on_event(model, test_id, output_dir, cfg):
     output_dir = Path(output_dir)
     output_dir.mkdir(exist_ok=True)
-    data_dir = Path(cfg.data.dir) #/ "test_images"
+    data_dir = Path(cfg.DATA.DIR) #/ "test_images"
 
     # orbKeyLen = len(test_id.split("_")[-1]) + 1 
     # event = test_id[:-orbKeyLen]
@@ -178,10 +201,10 @@ def apply_model_on_event(model, test_id, output_dir, cfg):
 
     print(f"------------------> {test_id} <-------------------")
 
-    predMask, probMask = inference(model, data_dir, event, cfg)
+    predMask = inference(model, data_dir, event, cfg)
 
     print(f"predMask shape: {predMask.shape}, unique: {np.unique(predMask)}")
-    print(f"probMask: [{probMask.min()}, {probMask.max()}]")
+    # print(f"probMask: [{probMask.min()}, {probMask.max()}]")
 
     # # mtbs_palette =  ["000000", "006400","7fffd4","ffff00","ff0000","7fff00"]
     # # [0,100/255,0]
@@ -212,7 +235,7 @@ def evaluate_model(cfg, model_url, output_dir):
     #     split_dict = json.load(json_file)
     # test_id_list = split_dict['test']['sarname']
 
-    test_id_list = [filename[:-4] for filename in os.listdir(Path(cfg.data.dir) / "S1" / "post")]
+    test_id_list = [filename[:-4] for filename in os.listdir(Path(cfg.DATA.DIR) / "S1" / "post")]
 
     model = torch.load(model_url)
     # output_dir = Path(SegModel.project_dir) / 'outputs'
@@ -236,7 +259,7 @@ def run_app(cfg : DictConfig) -> None:
     print(OmegaConf.to_yaml(cfg))
 
     # wandb.init(config=cfg, project=cfg.project.name, name=cfg.experiment.name)
-    wandb.init(config=cfg, project=cfg.project.name, entity=cfg.project.entity, name=cfg.experiment.name)
+    wandb.init(config=cfg, project=cfg.PROJECT.NAME, entity=cfg.PROJECT.ENTITY, name=cfg.EXP.NAME)
 
     # project_dir = Path(hydra.utils.get_original_cwd())
     #########################################################################
@@ -254,9 +277,9 @@ def run_app(cfg : DictConfig) -> None:
     # for test_id in test_id_list:
     #     apply_model_on_event(model, test_id, output_dir, satellites=['S1', 'S2'])
 
-    model_url = "/cephyr/NOBACKUP/groups/snic2021-7-104/puzhao-snic-500G/smp-seg-pytorch/outputs/run_s1s2_UNet_resnet18_['S1']_20211022T155051/model.pth"
+    model_url = "/home/p/u/puzhao/smp-seg-pytorch/outputs-igarss/run_s1s2_UNet_['S1']_EF_20220116T212807/model.pth"
     # output_dir = Path("/cephyr/NOBACKUP/groups/snic2021-7-104/puzhao-snic-500G/smp-seg-pytorch/outputs") / "errMap"
-    output_dir = Path("/cephyr/NOBACKUP/groups/snic2021-7-104/puzhao-snic-500G/smp-seg-pytorch") / cfg.experiment.output
+    output_dir = Path("/home/p/u/puzhao/wildfire-progression-dataset/CA_2021_Kamloops/outputs/pred_small")
     evaluate_model(cfg, model_url, output_dir)
     
     #########################################################################
@@ -271,4 +294,6 @@ if __name__ == "__main__":
     # output_dir = Path(f"G:/PyProjects/smp-seg-pytorch/outputs/test_output_s1s2_")
 
     # for test_id in test_id_list:
-    #     apply_model_on_event(model, test_id, output_dir, satellites=['S1', 'S2'])
\ No newline at end of file
+    #     apply_model_on_event(model, test_id, output_dir, satellites=['S1', 'S2'])
+
+    # scp -r puzhao@alvis1.c3se.chalmers.se:/cephyr/NOBACKUP/groups/snic2021-7-104/puzhao-snic-500G/CA_2021_Kamloops/S1/pre pre/
\ No newline at end of file
diff --git a/test.py b/test.py
index 6309d11..76e121b 100644
--- a/test.py
+++ b/test.py
@@ -196,12 +196,48 @@
 # print(np.mean(res['image']-res1["image"]))
 
 
+# import tifffile as tiff
+# from imageio import imread, imsave
+# import numpy as np
+# import random
+# from pathlib import Path
+# root_dir = Path("/home/p/u/puzhao/wildfire-s1s2-dataset-ca-tiles/test_images")
+# event = "CA_2019_NT_8"
+
+# pre = tiff.imread(root_dir / 'S2' / 'pre' / f"{event}.tif")
+# post = tiff.imread(root_dir / 'S2' / 'post' / f"{event}.tif")
+
+# def nbr(image):
+#     nir = image[3,]
+#     swir = image[5,]
+#     return (nir - swir)/(nir + swir)
+
+# dnbr = nbr(pre) - nbr(post)
 
-import torch
-import torch.nn.functional as F
+# imsave(f'{event}_dNBR.png', dnbr)
+# imsave(f'{event}_NBR_pre.png', nbr(pre))
+# imsave(f'{event}_NBR_post.png', nbr(post))
+# # imsave(f'{event}_dNBR_bin_0.1.png', (dnbr>0.1).astype(float))
 
-input = torch.randn(1,2,3,3)
-output = F.normalize(input, dim=1, p=2)
 
-print(input)
-print(output)
\ No newline at end of file
+import tifffile as tiff
+import numpy as np
+from pathlib import Path
+import os
+
+# data = tiff.imread("/home/p/u/puzhao/wildfire-s1s2-dataset-us-tiles/train/mask/mtbs/az3178211084220170423_3_3_.tif")
+# print(np.unique(data))
+
+# dataPath = Path("/home/p/u/puzhao/wildfire-s1s2-dataset-us-tiles/train")
+# s1_dir = Path("/home/p/u/puzhao/wildfire-s1s2-dataset-us-tiles/train/S1/post")
+# s2_dir = Path("/home/p/u/puzhao/wildfire-s1s2-dataset-us-tiles/train/S2/post")
+# print(len(os.listdir(s1_dir)))
+# print(len(os.listdir(s2_dir)))
+
+
+# import torch
+# x = torch.from_numpy(np.random.rand(10,1,3,3)).cuda()
+# print(x)
+
+img = tiff.imread("/home/p/u/puzhao/wildfire-progression-dataset/CA_2021_Kamloops/S2/post/20210907T19_S2.tif")
+print(img.shape)
diff --git a/utils/iou4all.py b/utils/iou4all.py
index af589fa..b836a4a 100644
--- a/utils/iou4all.py
+++ b/utils/iou4all.py
@@ -1,11 +1,12 @@
 
 
 import io
-import os
+import os, glob
 import numpy as np
 import torch
 from pathlib import Path
 from imageio import imread, imsave
+import tifffile as tiff
 import wandb
 
 # from smp.utils import train
@@ -14,20 +15,14 @@ def IoU_score(gt, pr, eps=1e-3):
     intersection = np.sum(gt * pr) # TP
     union = np.sum(gt) + np.sum(pr) - intersection + eps
 
-    # TP = np.sum(gt * pr)
-    # # TN = np.sum(gt * (1-pr))
-    # FP = np.sum((1 - gt) * pr)
-    # FN = np.sum((1 - gt) * (1 - pr))
-    
-    # iou = TP / (TP + FP + FN + eps)
-    # f1 = 2 * TP / (2 * TP + FP + FN + eps)
-    # return iou, f1, TP, FP, FN
-
     iou = intersection / union
     f1 = 2 * intersection / (intersection + union)
+    return [iou, f1, intersection, union]
 
-    return iou, f1, intersection, union
 
+################################################
+###### MTBS Two-Class IoU and F1-Score #######
+################################################
 
 def compute_IoU_F1(phase, result_dir, dataset_dir):
     event_dir = Path(f"{dataset_dir}/{phase}/S2/post")
@@ -42,7 +37,6 @@ def compute_IoU_F1(phase, result_dir, dataset_dir):
 
     step = 16 #len(eventList) #, valid batch size
 
-    eps = 1e-3
     results = []
     for i, event in enumerate(eventList):
         print()
@@ -50,13 +44,12 @@ def compute_IoU_F1(phase, result_dir, dataset_dir):
         gt = imread(result_dir / f"{event}_gts.png")[:,:,0] / 255
         pr = imread(result_dir / f"{event}_pred.png")[:,:,0] / 255
 
-        measure = IoU_score(gt, pr, eps=eps)
+        measure = IoU_score(gt, pr)
         results.append(measure)
 
         arr = np.array(results)
         # print(arr.shape)
         
-
         # method 1
         # IoU, F1, TP, FP, FN = np.sum(arr, axis=0)
 
@@ -104,11 +97,116 @@ def compute_IoU_F1(phase, result_dir, dataset_dir):
 
         wandb.log({'batch': {f'{phase}.avg_IoU': avg_batch_IoU, f'{phase}.avg_F1': avg_batch_F1}})
 
+
+################################################
+###### MTBS Multi-Class IoU and F1-Score #######
+################################################
+
+def mtbs_label_preprocess(label):
+    label[label==0] = 1 # both 0 and 1 are unburned
+    label[label==5] = 1 # treat 'greener' (5) as unburned
+    label[label==6] = 0 # ignore 'cloud' (6)
+    label = label - 1 # [4 classes in total: 0, 1, 2, 3], cloud: -1
+    return label
+
+def multiclass_IoU_F1(pred_dir, gts_dir, NUM_CLASS=4, phase='test_images'):
+
+    # gts_dir = Path(f"{dataset_dir}/{phase}/mask/mtbs")
+    TEST_MASK =  os.path.split(gts_dir)[-1]
+
+    eventList = [filename[:-4] for filename in os.listdir(gts_dir)]
+    eventList = sorted(eventList)
+
+    # initialize a dict to store results
+    results = {}
+    for cls in range(0, NUM_CLASS):
+        results[f'class{cls}'] = []
+    
+    # loop over all test events
+    for event in eventList:
+        print(event)
+
+        gt = tiff.imread(gts_dir / f"{event}.tif")
+        if 'mtbs' == TEST_MASK: gt = mtbs_label_preprocess(gt)
+        pr = tiff.imread(pred_dir / f"{event}_pred.tif")
+        
+        # compute IoU and F1 for each class per event
+        for cls in range(0, NUM_CLASS):
+            cls_gt = (gt==cls).astype(float)
+            cls_pr = (pr==cls).astype(float)
+
+            measure = IoU_score(cls_gt, cls_pr)
+            measure = measure + [cls_gt.sum()]
+            results[f'class{cls}'].append(measure)
+
+            print(f"class{cls} IoU: {measure[0]:.4f}, class{cls} F1: {measure[1]:.4f}")
+        
+        print()
+
+    # compute IoU and F1 for each class over all test images
+    class_IoUs = []
+    class_F1s = []
+    class_pixels = []
+    for key in results.keys():
+        arr = np.array(results[key]) # iou, f1, intersection, union, pixel number
+
+        # method 2
+        total_iou, total_f1, total_intersection, total_union, total_pixels = np.sum(arr, axis=0)
+        IoU = total_intersection / total_union
+        F1 = 2 * total_intersection / (total_intersection + total_union)
+
+        N = arr.shape[0]
+        print(f"-------------------- total metrics on {phase} -----------------------")
+        print(f"(dataset as a whole) {key} IoU: {IoU:.4f}, {key} F1: {F1:.4f}")
+        print(f"(average across events) {key} avg_IoU: {total_iou/N:.4f}, {key} avg_F1: {total_f1/N:.4f}")
+        print()
+
+        class_IoUs.append(IoU.round(4))
+        class_F1s.append(F1.round(4))
+        class_pixels.append(total_pixels)
+
+        # log results into wandb for each class
+        wandb.log({'final': {
+                f'{phase}.IoU_{key}': IoU, 
+                f'{phase}.F1_{key}': F1}
+            })
+
+    if NUM_CLASS == 2:
+        wandb.log({'final': {
+                f'{phase}.IoU': class_IoUs[-1], 
+                f'{phase}.F1': class_F1s[-1]}
+            })
+
+    mIoU = np.array(class_IoUs).mean()
+
+    # # Frequency-weighted IoU (FwIoU)
+    class_frequency = np.array(class_pixels) / np.array(class_pixels).sum()
+    FwIoU = (np.array(class_IoUs) * class_frequency).sum()
+
+    print(f"class IoU: {np.array(class_IoUs).round(4)}")
+    print(f"class frequency: {np.array(class_frequency).round(4)}")
+    print(f"mIoU: {mIoU:.4f}, FwIoU: {FwIoU:.4f}")
+
+    wandb.log({'final': {
+            f'{phase}.mIoU': mIoU,
+            f'{phase}.FwIoU': FwIoU
+        }
+    })
+
+
 if __name__ == "__main__":
 
     # Fresh
     phase = 'test_images'
-    dataset_dir = "/home/p/u/puzhao/wildfire-s1s2-dataset-ca-tiles"
-    result_dir = Path("/home/p/u/puzhao/smp-seg-pytorch/outputs/run_s1s2_UNet_['S2']_allBands_20220107T222557/errMap")
+    wandb.init(project='wildfire', name='test-multi-class-IoU')
+
+    # dataset_dir = "/home/p/u/puzhao/wildfire-s1s2-dataset-ca-tiles"
+    # result_dir = Path("/home/p/u/puzhao/smp-seg-pytorch/outputs_igarss/run_s1s2_UNet_['S1']_modis_20220204T181119/errMap")
+    # compute_IoU_F1(phase, result_dir, dataset_dir)
+
+
+    gts_dir = Path("/home/p/u/puzhao/wildfire-s1s2-dataset-us-tiles") / "test_images/mask/mtbs"
+    pred_dir = Path("/home/p/u/puzhao/smp-seg-pytorch/outputs/run_s1s2_UNet_['S2']_mtbs_20220227T233525_work/errMap")
+    multiclass_IoU_F1(pred_dir, gts_dir, NUM_CLASS=3)
 
-    compute_IoU_F1(phase, result_dir, dataset_dir)
\ No newline at end of file
+    wandb.finish()
\ No newline at end of file
