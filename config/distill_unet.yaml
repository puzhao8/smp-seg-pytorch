
# defaults:
#     - s1s2_unet: s1

project:
    name: IGARSS-2022
    entity: wildfire

data:
    # dir: /cephyr/NOBACKUP/groups/snic2021-7-104/wildfire-s1s2-dataset-ak-tiles
    # dir: /cephyr/NOBACKUP/groups/snic2021-7-104/wildfire-s1s2-dataset-ca-tiles
    # dir: D:\wildfire-s1s2-dataset-ak-tiles
    dir: /home/p/u/puzhao/wildfire-s1s2-dataset-ca-tiles

    name: s1s2
    satellites: ['S1','S2']
    prepost: ['pre', 'post']
    stacking: True # stack bi-temporal data

    ALL_BANDS:
        S1: ['ND', 'VH', 'VV']
        ALOS: ['ND', 'VH', 'VV']
        S2: ['B2', 'B3', 'B4', 'B8', 'B11', 'B12']

    INPUT_BANDS:
        S1: ['ND', 'VH', 'VV']
        ALOS: ['ND', 'VH', 'VV']
        # S2: ['B2', 'B3', 'B4', 'B8', 'B11', 'B12'] #['B4', 'B8', 'B12']
        S2: ['B4', 'B8', 'B12'] #['B4', 'B8', 'B12']

    useDataWoCAug: False
    SEED: 42
    random_state: 42

    # CLASSES: ['unburn', 'burned']
    CLASSES: ['burned']
    REF_MASK: poly
    train_ratio: 0.9

model:
    ARCH: distill_unet #FuseUNet, UNet
    TOPO: [16, 32, 64, 128]
    # LOSS_TYPE: SoftDiceLoss

    S2_PRETRAIN: /home/p/u/puzhao/smp-seg-pytorch/outputs/run_s1s2_distill_unet_S2_pretrain_B4812_20220108T164608/model.pth
    DISTILL: True
    LOSS_COEF: [0,0,0] # a * dice_loss + b * loss_do + c * loss_df
    ACTIVATION: sigmoid

    # For ResUNet only
    ENCODER: resnet18 # 'mobilenet_v2'
    ENCODER_WEIGHTS: imagenet

    max_epoch: 100
    batch_size: 16
    learning_rate: 1e-4
    weight_decay: 1e-4
    cross_domain_coef: 0

    use_lr_scheduler: True
    warmup_coef: 2
    
    max_score: 0.1 # If IoU > max_score, save model
    save_interval: 5 # save model frequency
    verbose: True

eval:
    patchsize: 512

experiment:
    note: 
    name: ${data.name}_${model.ARCH}_${data.satellites}_${experiment.note}
    output: ./outputs/run_${experiment.name}_${now:%Y%m%dT%H%M%S} #${defaults.0.data}

hydra:
    run:
        dir: ${experiment.output}